<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Knowledge_Vault]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>site-lib/media/favicon.png</url><title>Knowledge_Vault</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Sat, 04 Oct 2025 08:18:03 GMT</lastBuildDate><atom:link href="site-lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Sat, 04 Oct 2025 08:18:03 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[Pasted image 20251003212955]]></title><description><![CDATA[<img src="images/pasted-image-20251003212955.png" target="_self">]]></description><link>images/pasted-image-20251003212955.html</link><guid isPermaLink="false">Images/Pasted image 20251003212955.png</guid><pubDate>Sat, 04 Oct 2025 07:39:11 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[00 NNoM]]></title><description><![CDATA[
NNoM is a high-level inference Neural Network library specifically for microcontrollers.
<img alt="Pasted image 20251003212416.png" src="images/pasted-image-20251003212416.png" target="_self">
NNoM uses a layer-based structure. The most benefit is the model structure can seem directly from the codes.
It also makes the model conversion from other layer-based libs (Keras, TensorLayer, Caffe) to NNoM model very straight forward. When use&nbsp;generate_model(model, x_test, name='weights.h')&nbsp;to generate NNoM model, it simply read the configuration out and rewrite it to C codes.<br>
<img alt="Pasted image 20251003212955.png" src="images/pasted-image-20251003212955.png" target="_self">
NNoM uses a compiler to manage the layer structure and other resources. After compiling, all layers inside the model will be put into a shortcut list per the running order. Besides that, arguments will be filled in and the memory will be allocated to each layer (Memory are reused in between layers). Therefore, no memory allocation performed in the runtime, performance is the same as running backend function directly.
The NNoM is more on managing the higher-level structure, context argument and memory. The actual arithmetics are done by the backend functions.
<br>Currently, NNoM supports a pure C backend and CMSIS-NN backend. The CMSIS-NN is a highly optimized low-level NN core for ARM-Cortex-M microcontroller. Please check the&nbsp;<a data-tooltip-position="top" aria-label="https://majianjia.github.io/nnom/Porting_and_Optimisation_Guide/" rel="noopener nofollow" class="external-link is-unresolved" href="https://majianjia.github.io/nnom/Porting_and_Optimisation_Guide/" target="_self">optimization guide</a>&nbsp;for utilization.
NNoM is a higher-level inference framework. The most obvious feature is the human understandable interface.
It is also a layer-based framework, instead of operator-based. A layer might contain a few operators.
It natively supports complex model structure. High-efficiency network always benefited from complex structure.
It provides layer-to-layer analysis to help developer optimize their models. Notes: NNoM now supports both HWC and CHW formats. Some operation might not support both format currently. Please check the tables for the current status. Core LayersRNN LayersActivations<br>Activation can be used by itself as layer, or can be attached to the previous layer as&nbsp;<a data-tooltip-position="top" aria-label="https://majianjia.github.io/nnom/docs/A_Temporary_Guide_to_NNoM.md#addictionlly-activation-apis" rel="noopener nofollow" class="external-link is-unresolved" href="https://majianjia.github.io/nnom/docs/A_Temporary_Guide_to_NNoM.md#addictionlly-activation-apis" target="_self">"actail"</a>&nbsp;to reduce memory cost.There is no Struct API for activation currently, since activation are not usually used as a layer.Pooling LayersMatrix Operations LayersNNoM now use the local pure C backend implementation by default. Thus, there is no special dependency needed.NNoM currently only support 8 bit weights and 8 bit activations. The model will be quantised through model conversion&nbsp;generate_model(model, x_test, name='weights.h').The input data (activations) will need to be quantised then feed to the model.Performances vary from chip to chip. Efficiencies are more constant.We can use&nbsp;Multiply–accumulate operation (MAC) per Hz (MACops/Hz)&nbsp;to evaluate the efficiency. It simply means how many MAC can be done in one cycle.Currently, NNoM only count MAC operations on Convolution layers and Dense layers since other layers (pooling, padding) are much lesser.The script currently does not support implicit act:x = Dense(32, activation="relu")(x)
Use the explicit activation instead.x = Dense(32)(x)
x = Relu()(x)
Evaluation is equally important to building the model.<br>In NNoM, we provide a few different methods to evaluate the model. The details are list in&nbsp;<a data-tooltip-position="top" aria-label="https://majianjia.github.io/nnom/api_nnom_utils/" rel="noopener nofollow" class="external-link is-unresolved" href="https://majianjia.github.io/nnom/api_nnom_utils/" target="_self">Evaluation Methods</a>. If your system support print through a console (such as serial port), the evaluation can be printed on the console.Firstly, the model structure is printed during compiling in&nbsp;model_compile(), which is normally called in&nbsp;nnom_model_create().Secondly, the runtime performance is printed by&nbsp;model_stat().Thirdly, there is a set of&nbsp;prediction_*()&nbsp;APIs to validate a set of testing data and print out Top-K accuracy, confusion matrix and other info.This is what a typical model looks like in the&nbsp;weights.h&nbsp;or&nbsp;model.h&nbsp;or whatever you name it. These codes are generated by the script. In user's&nbsp;main(), call&nbsp;nnom_model_create()&nbsp;will create and compile the model./* nnom model */
static int8_t nnom_input_data[784];
static int8_t nnom_output_data[10];
static nnom_model_t* nnom_model_create(void)
{ static nnom_model_t model; nnom_layer_t* layer[20]; new_model(&amp;model); layer[0] = Input(shape(28, 28, 1), nnom_input_data); layer[1] = model.hook(Conv2D(12, kernel(3, 3), stride(1, 1), PADDING_SAME, &amp;conv2d_1_w, &amp;conv2d_1_b), layer[0]); layer[2] = model.active(act_relu(), layer[1]); layer[3] = model.hook(MaxPool(kernel(2, 2), stride(2, 2), PADDING_SAME), layer[2]); layer[4] = model.hook(Cropping(border(1,2,3,4)), layer[3]); layer[5] = model.hook(Conv2D(24, kernel(3, 3), stride(1, 1), PADDING_SAME, &amp;conv2d_2_w, &amp;conv2d_2_b), layer[4]); layer[6] = model.active(act_relu(), layer[5]); layer[7] = model.hook(MaxPool(kernel(4, 4), stride(4, 4), PADDING_SAME), layer[6]); layer[8] = model.hook(ZeroPadding(border(1,2,3,4)), layer[7]); layer[9] = model.hook(Conv2D(24, kernel(3, 3), stride(1, 1), PADDING_SAME, &amp;conv2d_3_w, &amp;conv2d_3_b), layer[8]); layer[10] = model.active(act_relu(), layer[9]); layer[11] = model.hook(UpSample(kernel(2, 2)), layer[10]); layer[12] = model.hook(Conv2D(48, kernel(3, 3), stride(1, 1), PADDING_SAME, &amp;conv2d_4_w, &amp;conv2d_4_b), layer[11]); layer[13] = model.active(act_relu(), layer[12]); layer[14] = model.hook(MaxPool(kernel(2, 2), stride(2, 2), PADDING_SAME), layer[13]); layer[15] = model.hook(Dense(64, &amp;dense_1_w, &amp;dense_1_b), layer[14]); layer[16] = model.active(act_relu(), layer[15]); layer[17] = model.hook(Dense(10, &amp;dense_2_w, &amp;dense_2_b), layer[16]); layer[18] = model.hook(Softmax(), layer[17]); layer[19] = model.hook(Output(shape(10,1,1), nnom_output_data), layer[18]); model_compile(&amp;model, layer[0], layer[19]); return &amp;model;
}
This is an example printed by&nbsp;model_compile(), which is normally called by&nbsp;nnom_model_create().Start compiling model...
Layer(#) Activation output shape ops(MAC) mem(in, out, buf) mem blk lifetime
-------------------------------------------------------------------------------------------------
#1 Input - - ( 28, 28, 1) ( 784, 784, 0) 1 - - - - - - - #2 Conv2D - ReLU - ( 28, 28, 12) 84k ( 784, 9408, 36) 1 1 1 - - - - - #3 MaxPool - - ( 14, 14, 12) ( 9408, 2352, 0) 1 1 1 - - - - - #4 Cropping - - ( 11, 7, 12) ( 2352, 924, 0) 1 1 - - - - - - #5 Conv2D - ReLU - ( 11, 7, 24) 199k ( 924, 1848, 432) 1 1 1 - - - - - #6 MaxPool - - ( 3, 2, 24) ( 1848, 144, 0) 1 1 1 - - - - - #7 ZeroPad - - ( 6, 9, 24) ( 144, 1296, 0) 1 1 - - - - - - #8 Conv2D - ReLU - ( 6, 9, 24) 279k ( 1296, 1296, 864) 1 1 1 - - - - - #9 UpSample - - ( 12, 18, 24) ( 1296, 5184, 0) 1 - 1 - - - - - #10 Conv2D - ReLU - ( 12, 18, 48) 2.23M ( 5184, 10368, 864) 1 1 1 - - - - - #11 MaxPool - - ( 6, 9, 48) ( 10368, 2592, 0) 1 1 1 - - - - - #12 Dense - ReLU - ( 64, 1, 1) 165k ( 2592, 64, 5184) 1 1 1 - - - - - #13 Dense - - ( 10, 1, 1) 640 ( 64, 10, 128) 1 1 1 - - - - - #14 Softmax - - ( 10, 1, 1) ( 10, 10, 0) 1 1 - - - - - - #15 Output - - ( 10, 1, 1) ( 10, 10, 0) 1 - - - - - - - -------------------------------------------------------------------------------------------------
Memory cost by each block: blk_0:5184 blk_1:2592 blk_2:10368 blk_3:0 blk_4:0 blk_5:0 blk_6:0 blk_7:0 Total memory cost by network buffers: 18144 bytes
Compling done in 179 ms It shows the run order, Layer names, activations, the output shape of the layer, the operation counts, the buffer size, and the memory block assignments.Later, it prints the maximum memory cost for each memory block. Since the memory block is shared between layers, the model only uses 3 memory blocks, altogether gives a sum memory cost by&nbsp;18144 Bytes.This is an example printed by&nbsp;model_stat().<br>
This method requires a microsecond timestamp porting, check&nbsp;<a data-tooltip-position="top" aria-label="https://majianjia.github.io/nnom/Porting_and_Optimisation_Guide/" rel="noopener nofollow" class="external-link is-unresolved" href="https://majianjia.github.io/nnom/Porting_and_Optimisation_Guide/" target="_self">porting guide</a>
Print running stat..
Layer(#) - Time(us) ops(MACs) ops/us --------------------------------------------------------
#1 Input - 11 #2 Conv2D - 5848 84k 14.47
#3 MaxPool - 698 #4 Cropping - 16 #5 Conv2D - 3367 199k 59.27
#6 MaxPool - 346 #7 ZeroPad - 36 #8 Conv2D - 4400 279k 63.62
#9 UpSample - 116 #10 Conv2D - 33563 2.23M 66.72
#11 MaxPool - 2137 #12 Dense - 2881 165k 57.58
#13 Dense - 16 640 40.00
#14 Softmax - 3 #15 Output - 1 Summary:
Total ops (MAC): 2970208(2.97M)
Prediction time :53439us
Efficiency 55.58 ops/us
NNOM: Total Mem: 20236 Calling this method will print out the time cost for each layer, and the efficiency in (MACops/us) of this layer.This is very important when designing your ad-hoc model.As mention, NNoM will allocate memory to the layer during the compiling phase. Memory block is a minimum unit for a layer to apply. For example, convolution layers normally apply one block for input data, one block for output data and one block for the intermediate data buffer.Layer(#) Activation output shape ops(MAC) mem(in, out, buf) mem blk lifetime
-------------------------------------------------------------------------------------------------
#2 Conv2D - ReLU - ( 28, 28, 12) 84k ( 784, 9408, 36) 1 1 1 - - - - - The example shows input buffer size&nbsp;784, output buffer size&nbsp;9408, intermediate buffer size&nbsp;36. The following&nbsp;mem blk lifetime&nbsp;means how long does the memory block last. All three block last only one step, they will be freed after the layer. In NNoM, the output memory will be pass directly to the next layer(s) as input buffer, so there is no memory copy cost and memory allocation in between layers.Lets say if we want to classify the MNIST hand writing dataset. This is what you normally do with Keras.model = Sequential()
model.add(Dense(32, input_dim=784))
model.add(Activation('relu'))
model.add(Dense(10))
Each operation in Keras are defined by "Layer", same as we did in NNoM. The terms are different from Tensorflow.After the&nbsp;model&nbsp;is trained, the weights and parameters are already functional. We can now convert it to C language files then put it in your MCU project.
The result of this step is a single&nbsp;weights.h&nbsp;file, which contains everything you need.
<br>To convert the model, NNoM has provided an simple API&nbsp;generate_model()<a data-tooltip-position="top" aria-label="https://majianjia.github.io/nnom/api_nnom_utils/" rel="noopener nofollow" class="external-link is-unresolved" href="https://majianjia.github.io/nnom/api_nnom_utils/" target="_self">API</a>&nbsp;to automatically do the job. Simply pass the&nbsp;model&nbsp;and the test dataset to it. It will do all the magics for you.generate_model(model, x_test, name='weights.h')
When the conversion is finished, you will find a new&nbsp;weights.h&nbsp;under your working folder. Simply copy the file to your MCU project, and call&nbsp;model = nnom_model_create();&nbsp;inside you&nbsp;main().Below is what you should do in practice.#include "nnom.h"
#include "weights.h" int main(void)
{ nnom_model_t *model; model = nnom_model_create(); model_run(model);
}
Then, your model is now running on you MCU. If you have supported&nbsp;printf&nbsp;on your MCU, you should see the compiling info on your consoles.Compiling logging similar to this:Start compiling model...
Layer(#) Activation output shape ops(MAC) mem(in, out, buf) mem blk lifetime
-------------------------------------------------------------------------------------------------
#1 Input - - ( 28, 28, 1) ( 784, 784, 0) 1 - - - - - - - #2 Conv2D - ReLU - ( 28, 28, 12) 84k ( 784, 9408, 36) 1 1 3 - - - - - #3 MaxPool - - ( 14, 14, 12) ( 9408, 2352, 0) 1 2 3 - - - - - #4 UpSample - - ( 28, 28, 12) ( 2352, 9408, 0) 1 2 2 - - - - - #5 Conv2D - - ( 14, 14, 12) 254k ( 2352, 2352, 432) 1 1 2 1 1 - - - #6 Conv2D - - ( 28, 28, 12) 1.01M ( 9408, 9408, 432) 1 1 2 1 1 - - - #7 Add - - ( 28, 28, 12) ( 9408, 9408, 0) 1 1 1 1 1 - - - #8 MaxPool - - ( 14, 14, 12) ( 9408, 2352, 0) 1 1 1 2 1 - - - #9 Conv2D - - ( 14, 14, 12) 254k ( 2352, 2352, 432) 1 1 1 2 1 - - - #10 AvgPool - - ( 7, 7, 12) ( 2352, 588, 168) 1 1 1 1 1 1 - - #11 AvgPool - - ( 14, 14, 12) ( 9408, 2352, 336) 1 1 1 1 1 1 - - #12 Add - - ( 14, 14, 12) ( 2352, 2352, 0) 1 1 - 1 1 1 - - #13 MaxPool - - ( 7, 7, 12) ( 2352, 588, 0) 1 1 1 2 - 1 - - #14 UpSample - - ( 14, 14, 12) ( 588, 2352, 0) 1 1 - 2 - 1 - - #15 Add - - ( 14, 14, 12) ( 2352, 2352, 0) 1 1 1 1 - 1 - - #16 MaxPool - - ( 7, 7, 12) ( 2352, 588, 0) 1 1 1 1 - 1 - - #17 Conv2D - - ( 7, 7, 12) 63k ( 588, 588, 432) 1 1 1 1 - 1 - - #18 Add - - ( 7, 7, 12) ( 588, 588, 0) 1 1 1 - - 1 - - #19 Concat - - ( 7, 7, 24) ( 1176, 1176, 0) 1 1 1 - - - - - #20 Dense - ReLU - ( 96, 1, 1) 112k ( 1176, 96, 2352) 1 1 1 - - - - - #21 Dense - - ( 10, 1, 1) 960 ( 96, 10, 192) 1 1 1 - - - - - #22 Softmax - - ( 10, 1, 1) ( 10, 10, 0) 1 - 1 - - - - - #23 Output - - ( 10, 1, 1) ( 10, 10, 0) 1 - - - - - - - -------------------------------------------------------------------------------------------------
Memory cost by each block: blk_0:9408 blk_1:9408 blk_2:9408 blk_3:9408 blk_4:2352 blk_5:588 blk_6:0 blk_7:0 Total memory cost by network buffers: 40572 bytes
Compling done in 76 ms You can now use the model to predict your data.
Firstly, filling the input buffer&nbsp;nnom_input_buffer[]&nbsp;with your own data(image, signals) which is defined in&nbsp;weights.h.
Secondly, call&nbsp;model_run(model);&nbsp;to do your prediction.
Thirdly, read your result from&nbsp;nnom_output_buffer[]. The maximum number is the results.
Now, please do check NNoM examples for more fancy methods.<br>Next <a data-href="01 ExecuTorch" href=".html" class="internal-link" target="_self" rel="noopener nofollow">01 ExecuTorch</a>]]></description><link>root/models/neural-network-libraries-for-embedded-systems/00-nnom.html</link><guid isPermaLink="false">Root/Models/Neural Network Libraries for Embedded Systems/00 NNoM.md</guid><pubDate>Sat, 04 Oct 2025 07:39:11 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003212416]]></title><description><![CDATA[<img src="images/pasted-image-20251003212416.png" target="_self">]]></description><link>images/pasted-image-20251003212416.html</link><guid isPermaLink="false">Images/Pasted image 20251003212416.png</guid><pubDate>Sat, 04 Oct 2025 07:39:11 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[01 Interconnect Fabric]]></title><description><![CDATA[The Interconnect Built in <a data-href="00 Basic 1 to 1 Interconnect" href="root/digital-design/interconnect/00-basic-1-to-1-interconnect.html" class="internal-link" target="_self" rel="noopener nofollow">00 Basic 1 to 1 Interconnect</a> only accommodates 1 Requestor and completer.Interconnect Protocol Vs Interconnect Fabric
The interconnect protocol affects the types of transactions that can occur between a given requestor–completer pair, whereas the interconnect fabric’s implementation affects the communication patterns that can occur among different requestor–completer pairs.
The naive method would be making many Requestor interfaces for each completer but that would incur a lot of logic and chip area. As you increase the number of requestors, things get problematic as you would need a complete bipartite graph topology between requestors and completers, this does not scale well.<br><img alt="Pasted image 20251003185851.png" src="images/pasted-image-20251003185851.png" target="_self">Thus we need something to Multiplex requestor signals to the needed completer. To do this we need to introduce an interconnect Fabric.<br><img alt="Pasted image 20251003190142.png" src="images/pasted-image-20251003190142.png" target="_self">This is an elegant solution that simply lets requestor address the completers using an ADDR signal to the interconnect fabric. This is called the address space. All interconnects contain an address decoder which takes care of address resolution, this is just a bunch of comparators.<br><img alt="Pasted image 20251003190823.png" src="images/pasted-image-20251003190823.png" target="_self">This arrangement of address decoder is very bulky, and introduces a long critical path reducing the interconnects maximum clock frequency. We can implement better address mapping to simplify the logic of address decoders.Lets propose only putting completers's address space on power of 2 addresses.<br><img alt="Pasted image 20251003191255.png" src="images/pasted-image-20251003191255.png" target="_self">This way, we can simplify our logic, and instead of using comparators for both the upper bound and lower bound of the address space, we can just compare the most significant bit eliminating the need for a comparator and a subtractor:<br><img alt="Pasted image 20251003191451.png" src="images/pasted-image-20251003191451.png" target="_self">]]></description><link>root/digital-design/interconnect/01-interconnect-fabric.html</link><guid isPermaLink="false">Root/Digital Design/Interconnect/01 Interconnect Fabric.md</guid><pubDate>Fri, 03 Oct 2025 16:16:50 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003191451]]></title><description><![CDATA[<img src="images/pasted-image-20251003191451.png" target="_self">]]></description><link>images/pasted-image-20251003191451.html</link><guid isPermaLink="false">Images/Pasted image 20251003191451.png</guid><pubDate>Fri, 03 Oct 2025 16:14:51 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003191255]]></title><description><![CDATA[<img src="images/pasted-image-20251003191255.png" target="_self">]]></description><link>images/pasted-image-20251003191255.html</link><guid isPermaLink="false">Images/Pasted image 20251003191255.png</guid><pubDate>Fri, 03 Oct 2025 16:12:55 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003190823]]></title><description><![CDATA[<img src="images/pasted-image-20251003190823.png" target="_self">]]></description><link>images/pasted-image-20251003190823.html</link><guid isPermaLink="false">Images/Pasted image 20251003190823.png</guid><pubDate>Fri, 03 Oct 2025 16:08:23 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[00 Basic 1 to 1 Interconnect]]></title><description><![CDATA[
This is more or less a summarization of Chapter 4, of Arm Fundamentals of SoC textbook Requestor &amp; Completer
The Component that is Requesting a resource/computation from another component, the completer, which completes this request.
ARM SoC: Single Word Transaction
The simplest form of transaction that we need an interconnect protocol to support is the movement of a single word from a requestor to a completer, that is, a single-word write transaction.
To Support Single Word Write Transaction we can simply add
The WR signal and the WRDATA are recieved on the same rising edge.
To Support Single Word Write Transaction we can simply add
The RD signal is received at rising edge 0 cycle 0, then the RDDATA on the next rising edge
<img alt="Pasted image 20251002163252.png" src="images/pasted-image-20251002163252.png" target="_self">Assumption &amp; disadvantages This assumes the completer can read/execute the request every clock cycle (1) We’ve assumed until now that there is only is one location, that is, only one register, in the completer (2) Asynchronous Reads
nothing prevents an interconnect protocol from permitting read data to be returned during cycle C (and, in fact, many protocols do allow this); however, this would imply that the overall read operation is asynchronous and we have stated that the interconnect we are building is synchronous.
<br><img alt="Pasted image 20251002164032.png" src="images/pasted-image-20251002164032.png" target="_self">A Major Disadvantage with the current interconnect that its support for back-to-back rapid transaction is lack-luster and leaves clock cycles to be optimized.
In the general case of a completer with an N-cycle end-to-end read latency, the maximum data throughput will be: To Mitigate this we can add a LENGTH Control Signal to signal to the completer how much data is given to it to write/read.<br><img alt="Pasted image 20251002164741.png" src="images/pasted-image-20251002164741.png" target="_self"><br><img alt="Pasted image 20251002164822.png" src="images/pasted-image-20251002164822.png" target="_self"><br>We Know <a data-tooltip-position="top" aria-label="^DW2" data-href="#^DW2" href="#^DW2" class="internal-link" target="_self" rel="noopener nofollow">Assumption (1)</a> is not true as the completer may need to process the request for many clock cycles.Terminiology
The mechanism through which a completer communicates its unavailability to a requestor is referred to as backpressure and a requestor waiting on a completer’s acknowledgement in this context is said to be stalled
To realize this feature, all we need is to implement a READY signal.
A transaction starts only when WR/RD and READY are both asserted in the same clock cycle.
Avoid Infinite Requestor Stalling
if a requestor wants to start a transaction, then it should assert its control signals and keep them asserted until the completer’s READY signal is asserted, Two Design Decesions are employed here: the requestor must not check the READY signal before deciding to assert its control signals because otherwise the completer may never know of the requestor’s intention to start a transaction
transactions cannot be interrupted once started because a requestor cannot deassert its control signals early, and all data words must be transmitted for both entities to acknowledge the transaction has finished. <br><img alt="Pasted image 20251002190522.png" src="images/pasted-image-20251002190522.png" target="_self">
Notice That the Completer Asserts/Deasserts the READY signal for each data write B C &amp; D.
Reading from completors may also incur many clock cycles, There needs to be a control signal that registers that the data within the RDDATA bus is valid.For a read transaction, the RD signal does not convey the validity of the RDDATA bus, but rather the validity of the control signals relevant to starting a transaction (ADDR, LENGTH). We need an additional completer-to-requestor signal to convey the validity of the RDDATA bus.
So RDDATAVALID is born: once completer fetches data, the RDDATAVALID, is asserted.
<br><img alt="Pasted image 20251002192210.png" src="images/pasted-image-20251002192210.png" target="_self"><br>Why would a Requestor Exert Backpressure on Completers? after all, shouldn’t a requestor know what it wants to write to the completer before initiating a burst transaction? This is the case when only a small amount of data needs transmitting, but if large amounts of data are involved some requestors may not know the extent of the payload they want to transmit at the outset. A common example would be a requestor reading from a FIFO.
<img alt="Pasted image 20251003182710.png" src="images/pasted-image-20251003182710.png" target="_self">
To Implement Requestor to Completer Backpressure, you can do this by deasserting the WR signal then asserting it again.<br><img alt="Pasted image 20251003183017.png" src="images/pasted-image-20251003183017.png" target="_self">We cannot Approach it as Write Transaction
Asserting RD when all of the data words from the previous transaction have not yet been received would be equivalent to the requestor telling the completer it wanted to start a new transaction as soon as the current one had terminated
Some protocols allow requestors to signal for completers future transactions, this done by giving the Completer a notice so that it can ensure its internal buffers accommodate the burst transaction.We are not those protocols so we will add a new signal RDDATAREADY which when deasserted by the requester, the requester can stall itself, and the completer will not assert new data in RDDATA bus unless RDDATAREADY is asserted again.<br><img alt="Pasted image 20251003184041.png" src="images/pasted-image-20251003184041.png" target="_self"><br>Next <a data-href="01 Interconnect Fabric" href="root/digital-design/interconnect/01-interconnect-fabric.html" class="internal-link" target="_self" rel="noopener nofollow">01 Interconnect Fabric</a>]]></description><link>root/digital-design/interconnect/00-basic-1-to-1-interconnect.html</link><guid isPermaLink="false">Root/Digital Design/Interconnect/00 Basic 1 to 1 Interconnect.md</guid><pubDate>Fri, 03 Oct 2025 16:02:59 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003190142]]></title><description><![CDATA[<img src="images/pasted-image-20251003190142.png" target="_self">]]></description><link>images/pasted-image-20251003190142.html</link><guid isPermaLink="false">Images/Pasted image 20251003190142.png</guid><pubDate>Fri, 03 Oct 2025 16:01:42 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003190025]]></title><description><![CDATA[<img src="images/pasted-image-20251003190025.png" target="_self">]]></description><link>images/pasted-image-20251003190025.html</link><guid isPermaLink="false">Images/Pasted image 20251003190025.png</guid><pubDate>Fri, 03 Oct 2025 16:00:25 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003185851]]></title><description><![CDATA[<img src="images/pasted-image-20251003185851.png" target="_self">]]></description><link>images/pasted-image-20251003185851.html</link><guid isPermaLink="false">Images/Pasted image 20251003185851.png</guid><pubDate>Fri, 03 Oct 2025 15:58:51 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003184213]]></title><description><![CDATA[<img src="images/pasted-image-20251003184213.png" target="_self">]]></description><link>images/pasted-image-20251003184213.html</link><guid isPermaLink="false">Images/Pasted image 20251003184213.png</guid><pubDate>Fri, 03 Oct 2025 15:42:13 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003184041]]></title><description><![CDATA[<img src="images/pasted-image-20251003184041.png" target="_self">]]></description><link>images/pasted-image-20251003184041.html</link><guid isPermaLink="false">Images/Pasted image 20251003184041.png</guid><pubDate>Fri, 03 Oct 2025 15:40:41 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003183017]]></title><description><![CDATA[<img src="images/pasted-image-20251003183017.png" target="_self">]]></description><link>images/pasted-image-20251003183017.html</link><guid isPermaLink="false">Images/Pasted image 20251003183017.png</guid><pubDate>Fri, 03 Oct 2025 15:30:17 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003182710]]></title><description><![CDATA[<img src="images/pasted-image-20251003182710.png" target="_self">]]></description><link>images/pasted-image-20251003182710.html</link><guid isPermaLink="false">Images/Pasted image 20251003182710.png</guid><pubDate>Fri, 03 Oct 2025 15:27:10 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[02 AHB-Lite Protocol]]></title><link>root/digital-design/interconnect/02-ahb-lite-protocol.html</link><guid isPermaLink="false">Root/Digital Design/Interconnect/02 AHB-Lite Protocol.md</guid><pubDate>Thu, 02 Oct 2025 13:06:44 GMT</pubDate></item><item><title><![CDATA[00 Basic Interconnect]]></title><description><![CDATA[
This is more or less a summarization of Chapter 4, of Arm Fundamentals of SoC textbook Requestor &amp; Completer
The Component that is Requesting a resource/computation from another component, the completer, which completes this request.
ARM SoC: Single Word Transaction
The simplest form of transaction that we need an interconnect protocol to support is the movement of a single word from a requestor to a completer, that is, a single-word write transaction.
To Support Single Word Write Transaction we can simply add
The WR signal and the WRDATA are recieved on the same rising edge.
To Support Single Word Write Transaction we can simply add
The RD signal is received at rising edge 0 cycle 0, then the RDDATA on the next rising edge
<img alt="Pasted image 20251002163252.png" src="images/pasted-image-20251002163252.png" target="_self">Assumption &amp; disadvantages This assumes the completer can read/execute the request every clock cycle (1) We’ve assumed until now that there is only is one location, that is, only one register, in the completer (2) Asynchronous Reads
nothing prevents an interconnect protocol from permitting read data to be returned during cycle C (and, in fact, many protocols do allow this); however, this would imply that the overall read operation is asynchronous and we have stated that the interconnect we are building is synchronous.
<br><img alt="Pasted image 20251002164032.png" src="images/pasted-image-20251002164032.png" target="_self">A Major Disadvantage with the current interconnect that its support for back-to-back rapid transaction is lack-luster and leaves clock cycles to be optimized.
In the general case of a completer with an N-cycle end-to-end read latency, the maximum data throughput will be: To Mitigate this we can add a LENGTH Control Signal to signal to the completer how much data is given to it to write/read.<br><img alt="Pasted image 20251002164741.png" src="images/pasted-image-20251002164741.png" target="_self"><br><img alt="Pasted image 20251002164822.png" src="images/pasted-image-20251002164822.png" target="_self"><br>We Know <a data-tooltip-position="top" aria-label="^DW2" data-href="#^DW2" href="#^DW2" class="internal-link" target="_self" rel="noopener nofollow">Assumption (1)</a> is not true as the completer may need to process the request for many clock cycles.Terminiology
The mechanism through which a completer communicates its unavailability to a requestor is referred to as backpressure and a requestor waiting on a completer’s acknowledgement in this context is said to be stalled
To realize this feature, all we need is to implement a READY signal.
A transaction starts only when WR/RD and READY are both asserted in the same clock cycle.
Avoid Infinite Requestor Stalling
if a requestor wants to start a transaction, then it should assert its control signals and keep them asserted until the completer’s READY signal is asserted, Two Design Decesions are employed here: the requestor must not check the READY signal before deciding to assert its control signals because otherwise the completer may never know of the requestor’s intention to start a transaction
transactions cannot be interrupted once started because a requestor cannot deassert its control signals early, and all data words must be transmitted for both entities to acknowledge the transaction has finished. <br><img alt="Pasted image 20251002190522.png" src="images/pasted-image-20251002190522.png" target="_self">
Notice That the Completer Asserts/Deasserts the READY signal for each data write B C &amp; D.
Reading from completors may also incur many clock cycles, There needs to be a control signal that registers that the data within the RDDATA bus is valid.For a read transaction, the RD signal does not convey the validity of the RDDATA bus, but rather the validity of the control signals relevant to starting a transaction (ADDR, LENGTH). We need an additional completer-to-requestor signal to convey the validity of the RDDATA bus.
So RDDATAVALID is born: once completer fetches data, the RDDATAVALID, is asserted.
<br><img alt="Pasted image 20251002192210.png" src="images/pasted-image-20251002192210.png" target="_self"><br>Next <a data-href="01 AHB-Lite Protocol" href="root/digital-design/interconnect/01-ahb-lite-protocol.html" class="internal-link" target="_self" rel="noopener nofollow">01 AHB-Lite Protocol</a>]]></description><link>root/digital-design/interconnect/00-basic-interconnect.html</link><guid isPermaLink="false">Root/Digital Design/Interconnect/00 Basic Interconnect.md</guid><pubDate>Fri, 03 Oct 2025 14:47:51 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251002192210]]></title><description><![CDATA[<img src="images/pasted-image-20251002192210.png" target="_self">]]></description><link>images/pasted-image-20251002192210.html</link><guid isPermaLink="false">Images/Pasted image 20251002192210.png</guid><pubDate>Thu, 02 Oct 2025 16:22:10 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251002190522]]></title><description><![CDATA[<img src="images/pasted-image-20251002190522.png" target="_self">]]></description><link>images/pasted-image-20251002190522.html</link><guid isPermaLink="false">Images/Pasted image 20251002190522.png</guid><pubDate>Thu, 02 Oct 2025 16:05:22 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251002164822]]></title><description><![CDATA[<img src="images/pasted-image-20251002164822.png" target="_self">]]></description><link>images/pasted-image-20251002164822.html</link><guid isPermaLink="false">Images/Pasted image 20251002164822.png</guid><pubDate>Thu, 02 Oct 2025 13:48:22 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251002164741]]></title><description><![CDATA[<img src="images/pasted-image-20251002164741.png" target="_self">]]></description><link>images/pasted-image-20251002164741.html</link><guid isPermaLink="false">Images/Pasted image 20251002164741.png</guid><pubDate>Thu, 02 Oct 2025 13:47:41 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251002164032]]></title><description><![CDATA[<img src="images/pasted-image-20251002164032.png" target="_self">]]></description><link>images/pasted-image-20251002164032.html</link><guid isPermaLink="false">Images/Pasted image 20251002164032.png</guid><pubDate>Thu, 02 Oct 2025 13:40:32 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251002163252]]></title><description><![CDATA[<img src="images/pasted-image-20251002163252.png" target="_self">]]></description><link>images/pasted-image-20251002163252.html</link><guid isPermaLink="false">Images/Pasted image 20251002163252.png</guid><pubDate>Thu, 02 Oct 2025 13:32:52 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[00 Basic Interconnect]]></title><description><![CDATA[
This is more or less a summarization of Chapter 4, of Arm Fundamentals of SoC textbook Requestor &amp; Completer
The Component that is Requesting a resource/computation from another component, the completer, which completes this request.
ARM SoC: Single Word Transaction
The simplest form of transaction that we need an interconnect protocol to support is the movement of a single word from a requestor to a completer, that is, a single-word write transaction.
To Support Single Word Write Transaction we can simply add
The WR signal and the WRDATA are recieved on the same rising edge.
To Support Single Word Write Transaction we can simply add
The RD signal is received at rising edge 0 cycle 0, then the RDDATA on the next rising edge
“Pasted image 20251002163252.png” could not be found.Assumption &amp; disadvantages This assumes the completer can read/execute the request every clock cycle (1) We’ve assumed until now that there is only is one location, that is, only one register, in the completer (2) Asynchronous Reads
nothing prevents an interconnect protocol from permitting read data to be returned during cycle C (and, in fact, many protocols do allow this); however, this would imply that the overall read operation is asynchronous and we have stated that the interconnect we are building is synchronous.
“Pasted image 20251002164032.png” could not be found.A Major Disadvantage with the current interconnect that its support for back-to-back rapid transaction is lack-luster and leaves clock cycles to be optimized.
In the general case of a completer with an N-cycle end-to-end read latency, the maximum data throughput will be: To Mitigate this we can add a LENGTH Control Signal to signal to the completer how much data is given to it to write/read.“Pasted image 20251002164741.png” could not be found.“Pasted image 20251002164822.png” could not be found.We Know <a data-tooltip-position="top" aria-label="^DW2" data-href="#^DW2" href="#^DW2" class="internal-link" target="_self" rel="noopener nofollow">Assumption (1)</a> is not true as the completer may need to process the request for many clock cycles.Terminiology
The mechanism through which a completer communicates its unavailability to a requestor is referred to as backpressure and a requestor waiting on a completer’s acknowledgement in this context is said to be stalled
To realize this feature, all we need is to implement a READY signal.
A transaction starts only when WR/RD and READY are both asserted in the same clock cycle.
Avoid Infinite Requestor Stalling
if a requestor wants to start a transaction, then it should assert its control signals and keep them asserted until the completer’s READY signal is asserted, Two Design Decesions are employed here: the requestor must not check the READY signal before deciding to assert its control signals because otherwise the completer may never know of the requestor’s intention to start a transaction
transactions cannot be interrupted once started because a requestor cannot deassert its control signals early, and all data words must be transmitted for both entities to acknowledge the transaction has finished. “Pasted image 20251002190522.png” could not be found.
Notice That the Completer Asserts/Deasserts the READY signal for each data write B C &amp; D.
Reading from completors may also incur many clock cycles, There needs to be a control signal that registers that the data within the RDDATA bus is valid.For a read transaction, the RD signal does not convey the validity of the RDDATA bus, but rather the validity of the control signals relevant to starting a transaction (ADDR, LENGTH). We need an additional completer-to-requestor signal to convey the validity of the RDDATA bus.
So RDDATAVALID is born: once completer fetches data, the RDDATAVALID, is asserted.
“Pasted image 20251002192210.png” could not be found.<br>Next <a data-href="01 AHB-Lite Protocol" href="root/digital-design/interconnect/01-ahb-lite-protocol.html" class="internal-link" target="_self" rel="noopener nofollow">01 AHB-Lite Protocol</a>]]></description><link>root/digital-design/interconnect/00-basic-interconnect.html</link><guid isPermaLink="false">root/Digital Design/Interconnect/00 Basic Interconnect.md</guid><pubDate>Thu, 02 Oct 2025 16:34:10 GMT</pubDate></item><item><title><![CDATA[Iverilog & GtkWave Simulation]]></title><description><![CDATA[Make Sure your test-bench dumps waveform .vcd in the output, by appending: initial
begin $dumpfile("&lt;module name&gt;_tb.vcd"); $dumpvars(0,test);
end
$ iverilog -o &lt;output_filename&gt; &lt;testbench&gt;.v &lt;verilog_sources&gt;.v $ vvp &lt;output_filename&gt; $ gtkwave &lt;vcd_filename&gt;.vcd &amp;
Directory structure-rw-rw-r-- 1 waseem waseem 939 Oct 2 14:43 ahbl_master_tb.v
-rw-rw-r-- 1 waseem waseem 291 Oct 2 14:43 readme.md
drwxrwxr-x 2 waseem waseem 4.0K Oct 2 14:55 src/
iverilog -o out ahbl_master_tb.v src/ahbl_master.v src/ahbl_slave.v src/ahbl_splitter_4.v
OR you can use -I Option or wildcards *iverilog -o out ahbl_master_tb.v src/*.v
gtkwave &lt;vcd_filename&gt;.vcd &amp;
# Source files
V_SOURCES = $(wildcard src/*.v)
TB_SOURCE = ahbl_master_tb.v # Output files
OUT_FILE = out
# Nasty string concatenation trick to maintain consistency
VCD_FILE = $(TB_SOURCE)cd # Default target: runs the simulation and opens the waveform
all: wave # Compile the Verilog sources
$(OUT_FILE): $(V_SOURCES) $(TB_SOURCE) iverilog -o $(OUT_FILE) $(TB_SOURCE) $(V_SOURCES) # Run the simulation to generate the VCD file
$(VCD_FILE): $(OUT_FILE) vvp $(OUT_FILE) # Target to run the simulation
sim: $(VCD_FILE) # Open the waveform in GTKWave
wave: $(VCD_FILE) gtkwave $(VCD_FILE) &amp; # Clean up generated files
clean: rm -f $(OUT_FILE) $(VCD_FILE)
]]></description><link>root/digital-design/iverilog-&amp;-gtkwave-simulation.html</link><guid isPermaLink="false">root/Digital Design/Iverilog &amp; GtkWave Simulation.md</guid><pubDate>Thu, 02 Oct 2025 16:12:58 GMT</pubDate></item><item><title><![CDATA[GDB]]></title><description><![CDATA[g++ &lt;file-name&gt; -g -o &lt;executable-name&gt;-g debugging symbols
-o output executablerun
lay nextbr &lt;symbol (file,method,variable,line)&gt;info &lt;command&gt;
info break : show breakpoints enable 1 : enable (ID of breakpoint)
disable 1 : disable (ID of breakpoint)Overloaded functions when putting a breakpoint on an overloaded function GDB will put the breakpoints on all the functions of the same name
print &lt;var&gt;
inspect &lt;stl structure&gt;set &lt;var&gt; = &lt;value&gt;nsfincontinue or cneed -lpthread flag when compilinginfo threads or thswitching threads
t &lt;id&gt; backtrace of the thread
btswitching frames
f &lt;id&gt;b &lt;function&gt; if &lt;variable&gt; &lt;operator&gt; &lt;value&gt;break on function if condition met--release and --g flagscompiler optimization flags-03
-02
-01 (Default) -g3 debugging with optimiation level 3
]]></description><link>root/debugging/gdb.html</link><guid isPermaLink="false">root/Debugging/GDB.md</guid><pubDate>Thu, 02 Oct 2025 16:05:14 GMT</pubDate></item><item><title><![CDATA[01 AHB-Lite Protocol]]></title><link>root/digital-design/interconnect/01-ahb-lite-protocol.html</link><guid isPermaLink="false">root/Digital Design/Interconnect/01 AHB-Lite Protocol.md</guid><pubDate>Thu, 02 Oct 2025 13:06:44 GMT</pubDate></item></channel></rss>