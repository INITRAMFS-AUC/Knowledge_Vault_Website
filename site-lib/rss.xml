<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Knowledge_Vault]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>site-lib/media/favicon.png</url><title>Knowledge_Vault</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Sat, 04 Oct 2025 17:29:37 GMT</lastBuildDate><atom:link href="site-lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Sat, 04 Oct 2025 17:29:36 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[02 AHB-Lite]]></title><description><![CDATA[
This is more or less a summarization of Chapter 5, of Arm Fundamentals of SoC textbook, with note author's input
Real World On-chip Buses Real World Off-chip Buses SoCs use on-chip buses, as all their components reside on the same die Originally developed by ARM but then became an open standard.
(Advanced High-Performance Bus Lite) AHB-Lite and (Advanced Peripheral Bus) APB completers are often used together in a system to allow high-performance subsystems to communicate through AHB-Lite, while low-power subsystems interface with their higher-power counterparts using the slower APB protocol to save power.<img alt="Pasted image 20251004133655.png" src="images/pasted-image-20251004133655.png" target="_self">Instead of requestors and completers, another terminology is used, Managers and Subordinates.AHB-Lite provides an alternative solution to this bus utilization challenge by allowing managers to issue bus operations in a pipelined fashion. Thus, each operation consists of two phases:
an address phase,
a data phase.
To support even higher bandwidth, AHB-lite utilizes wide data buses.<br><img alt="Pasted image 20251004135016.png" src="images/pasted-image-20251004135016.png" target="_self">Some High-Level Observations supports power-of-two bus sizes that range from 8 to 1024 bits.
There are extra signals on the Subordinate side, HREADY and HSEL, that is because multiple subordinates can be connected to the same manager and the AHB-Lite protocol designers decided to expose the extra signaling to handle this multiplicity on the subordinate side of the interconnect. <br><img alt="Pasted image 20251004153340.png" src="images/pasted-image-20251004153340.png" target="_self">
Notice that the HREADY signals from subordinate side are many while it is only one on the manager side, that is because if one completer is still carrying out a request on the bus it needs to finish before the next request is issued, this ensures requests are carried out in order in the pipelined nature of this implementation.
<br>The address decoder is combinational, that means it is stateless yet the multiplexer must be stateful, the multiplexer must be stateful to avoid the infinite stalling problem outlined in <a data-tooltip-position="top" aria-label="00 Basic 1 to 1 Interconnect > ^e99960" data-href="00 Basic 1 to 1 Interconnect#^e99960" href="root/digital-design/interconnect/00-basic-1-to-1-interconnect.html#^e99960" class="internal-link" target="_self" rel="noopener nofollow">00 Basic 1 to 1 Interconnect</a>
HSELx is outputted from address decoder, it selects the correct subordinate based on the address requested from the manager.
<br>In contrast to the implementation in <a data-href="00 Basic 1 to 1 Interconnect" href="root/digital-design/interconnect/00-basic-1-to-1-interconnect.html" class="internal-link" target="_self" rel="noopener nofollow">00 Basic 1 to 1 Interconnect</a>, we do not have a RD signal to subordinates, that is because we can use the off signal of HWRITE to signify read operations.
Due to the binary nature of the HWRITE signal, we cannot put bus in idle Assume these set of Write operations <br><img alt="Pasted image 20251004162523.png" src="images/pasted-image-20251004162523.png" target="_self"><br><img alt="Pasted image 20251004163118.png" src="images/pasted-image-20251004163118.png" target="_self">HTRANS is a 2-bit signal sent from the manager to the subordinate to indicate the type of transfer being requested. Operation of HTRANS signal:<br><img alt="Pasted image 20251004164601.png" src="images/pasted-image-20251004164601.png" target="_self">Assume we are saving uint8_t or uint16_t in C, this operation would consume a lot of bus cycles if it is emulated as the data bus width would be fixed to 32 bit data buses, therefore we need a way for the requestor to signal to the completer the size of the data transaction so it can be done in one bus cycle.HSIZE, a 3-bit signal that indicates the size of a single transfer in bytes. <br><img alt="Pasted image 20251004170856.png" src="images/pasted-image-20251004170856.png" target="_self"><br>In <a data-href="00 Basic 1 to 1 Interconnect" href="root/digital-design/interconnect/00-basic-1-to-1-interconnect.html" class="internal-link" target="_self" rel="noopener nofollow">00 Basic 1 to 1 Interconnect</a> bursts were introduced to allow back-to-back transactions, but this is already enabled by default by the pipelined nature of AHB-Lite, however bursts are supported because this can allow completers to prepare their internals for the data given in bursts possibly relieving some backpressure exerted on requester.Each bus burst transfer is called a beat by AMBA.Incrementing bursts The address of the next beat is computed as , i.e. successive beats always have incrementing addresses. Wrapping bursts The address of the next beat is computed as , i.e. successive beats’ addresses wrap when they cross an address (or block-size) boundary defined by the product of the number of beats (defined by HBURST) and the data width (in bytes; defined by HSIZE). Warning
Note that the total amount of data transferred in a burst is defined by multiplying the number of beats by the amount of data in each beat (as conveyed through the HSIZE bus). This definition implies that HSIZE must remain constant throughout the burst and that the manager cannot change the data width between beats.
<br><img alt="Pasted image 20251004174720.png" src="images/pasted-image-20251004174720.png" target="_self">
During a data phase, subordinates can deassert HREADY to insert wait states if they require more time to respond to a transfer, with the address phase of the next transfer only accepted when HREADY is high again.
Due to the pipelined nature of AHB-Lite, Address phase cannot be stalled
However, does it make sense for the manager to stall a single word transaction, it should support the word widths that it requests, otherwise it would use SEQ state.
Also, does it make sense for the manager to stall an IDLE state, it would just stall itself this way.
So AHB-Lite only supports stalling for burst transactions were the manager runs out of memory in internal buffers.
<br><img alt="Pasted image 20251004195232.png" src="images/pasted-image-20251004195232.png" target="_self"><br><img alt="Pasted image 20251004201722.png" src="images/pasted-image-20251004201722.png" target="_self">The D and A components are the address decoder and the arbiter (a mux possibly?)What would happen if M1 and M2 try to access the Same resource, say S1?HMASTLOCKHRESPHPROT]]></description><link>root/digital-design/interconnect/02-ahb-lite.html</link><guid isPermaLink="false">Root/Digital Design/Interconnect/02 AHB-Lite.md</guid><pubDate>Sat, 04 Oct 2025 17:24:35 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251004201722]]></title><description><![CDATA[<img src="images/pasted-image-20251004201722.png" target="_self">]]></description><link>images/pasted-image-20251004201722.html</link><guid isPermaLink="false">Images/Pasted image 20251004201722.png</guid><pubDate>Sat, 04 Oct 2025 17:17:22 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251004195232]]></title><description><![CDATA[<img src="images/pasted-image-20251004195232.png" target="_self">]]></description><link>images/pasted-image-20251004195232.html</link><guid isPermaLink="false">Images/Pasted image 20251004195232.png</guid><pubDate>Sat, 04 Oct 2025 16:52:32 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251004174720]]></title><description><![CDATA[<img src="images/pasted-image-20251004174720.png" target="_self">]]></description><link>images/pasted-image-20251004174720.html</link><guid isPermaLink="false">Images/Pasted image 20251004174720.png</guid><pubDate>Sat, 04 Oct 2025 14:47:20 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[01 Interconnect Fabric]]></title><description><![CDATA[The Interconnect Built in <a data-href="00 Basic 1 to 1 Interconnect" href="root/digital-design/interconnect/00-basic-1-to-1-interconnect.html" class="internal-link" target="_self" rel="noopener nofollow">00 Basic 1 to 1 Interconnect</a> only accommodates 1 Requestor and completer.Interconnect Protocol Vs Interconnect Fabric
The interconnect protocol affects the types of transactions that can occur between a given requestor–completer pair, whereas the interconnect fabric’s implementation affects the communication patterns that can occur among different requestor–completer pairs.
The naive method would be making many Requestor interfaces for each completer but that would incur a lot of logic and chip area. As you increase the number of requestors, things get problematic as you would need a complete bipartite graph topology between requestors and completers, this does not scale well.<br><img alt="Pasted image 20251003185851.png" src="images/pasted-image-20251003185851.png" target="_self">Thus we need something to Multiplex requestor signals to the needed completer. To do this we need to introduce an interconnect Fabric.<br><img alt="Pasted image 20251003190142.png" src="images/pasted-image-20251003190142.png" target="_self">This is an elegant solution that simply lets requestor address the completers using an ADDR signal to the interconnect fabric. This is called the address space. All interconnects contain an address decoder which takes care of address resolution, this is just a bunch of comparators.<br><img alt="Pasted image 20251003190823.png" src="images/pasted-image-20251003190823.png" target="_self">This arrangement of address decoder is very bulky, and introduces a long critical path reducing the interconnects maximum clock frequency. We can implement better address mapping to simplify the logic of address decoders.Lets propose only putting completers's address space on power of 2 addresses.<br><img alt="Pasted image 20251003191255.png" src="images/pasted-image-20251003191255.png" target="_self">This way, we can simplify our logic, and instead of using comparators for both the upper bound and lower bound of the address space, we can just compare the most significant bit eliminating the need for a comparator and a subtractor:<br><img alt="Pasted image 20251003191451.png" src="images/pasted-image-20251003191451.png" target="_self">When dealing with multiple requestors it is not uncommon to have two requestors request a signal from a completer at the same time. Therefore there must be an intermediary entity, an arbiter that takes into account requestor requests.Shared bus architectures are viable when all completers and requestors share the same interconnect protocol interfaces. <br><img alt="Pasted image 20251004114249.png" src="images/pasted-image-20251004114249.png" target="_self">
All requestor and completer interconnect interfaces have to be guarded by a tri-state gate because only a single requestor–completer pair can be connected to the bus at any given time.
Implementation Note
we need instead to use an additional out-of-protocol signal between the requestors and the arbiter for this purpose (thus, shared buses use requestor-side arbitration).
The arbiter receives all requestor requests and sequentially grants bus access by enabling the specific requestor and completer’s tri-state gates.
Advantages Easy to Implement
Can operate at high clock speed
Economical in Hardware resources Disadvantages
Does not Support any notion of concurrency, i.e, requestors cannot communicate with different completers in parallel.
Quote
Shared-bus architectures can therefore cause requestors in a systems to spend a significant amount of time waiting for access to the bus, and waiting times get worse the more requestors exist in the system, which is an unfavorable situation for SoCs, which often contain many independent accelerator units that act as requestors. Shared-bus architectures are, therefore, rarely used in SoCs. Full Crossbar-Switch Architectures are Completer-side arbitration and this allows for maximum concurrency in the system.<br><img alt="Pasted image 20251004115810.png" src="images/pasted-image-20251004115810.png" target="_self">
On the left Completers Switches 2-SW are closed as there is no requestor collision, On the right Completer's Switch is now open as there is requestor collision. Implementation Note "full crossbar switches do not require any extra out-of-protocol signals for arbitration purposes because each switch can see when multiple transactions are simultaneously directed at the same completer and can automatically provide backpressure on all requestors except the one that was granted access to the completer. Therefore, the interconnect protocol itself acts as the arbitration mechanism"
The Crossbar logic itself defines the arbitration policy: this can be round-robin priority of requestors, or priority access, basically a scheduler.
disadvantages
Full Cross-bar switches require a lot of resources area-wise on the die. The area of the cross-bar switch grows quadratically with the number of requestors and completers in the system. (as it is basically a square matrix of sitches)
Quote
In real-world SoCs, some requestors may only ever need connectivity to a subset of the system’s available completers. For example, while a CPU may need to be connected to most peripherals, a DMA unit may only need interconnection with memories. <br><img alt="Pasted image 20251004123946.png" src="images/pasted-image-20251004123946.png" target="_self">
Each completer switch is sized to only accommodate the requestors that communicate with it.
Advantages <br>Offers all the advantages of <a data-href="#Full Crossbar-Switch Architecture" href="root/digital-design/interconnect/01-interconnect-fabric.html#Full_Crossbar-Switch_Architecture_0" class="internal-link" target="_self" rel="noopener nofollow">Full Crossbar-Switch Architecture</a> Less die area than that of the Full Crossbar-Switch <br><img alt="Pasted image 20251004125857.png" src="images/pasted-image-20251004125857.png" target="_self"><br>Just like in software, your interconnect fabric can act as an adapter following the adapter design pattern, for example, if a completer does not support <a data-tooltip-position="top" aria-label="00 Basic 1 to 1 Interconnect > ^2d40f7" data-href="00 Basic 1 to 1 Interconnect#^2d40f7" href="root/digital-design/interconnect/00-basic-1-to-1-interconnect.html#^2d40f7" class="internal-link" target="_self" rel="noopener nofollow">Burst Transactions</a>, the interconnect fabric should be tasked with converted burst transaction to <a data-tooltip-position="top" aria-label="00 Basic 1 to 1 Interconnect > ^cb00a1" data-href="00 Basic 1 to 1 Interconnect#^cb00a1" href="root/digital-design/interconnect/00-basic-1-to-1-interconnect.html#^cb00a1" class="internal-link" target="_self" rel="noopener nofollow">Single Word Transactions</a> the completer can understand, while stalling the requestor through its interface if needed.<br>For real world examples on Interconnects: <a data-href="02 AHB-Lite" href="root/digital-design/interconnect/02-ahb-lite.html" class="internal-link" target="_self" rel="noopener nofollow">02 AHB-Lite</a>]]></description><link>root/digital-design/interconnect/01-interconnect-fabric.html</link><guid isPermaLink="false">Root/Digital Design/Interconnect/01 Interconnect Fabric.md</guid><pubDate>Sat, 04 Oct 2025 14:36:11 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251004170856]]></title><description><![CDATA[<img src="images/pasted-image-20251004170856.png" target="_self">]]></description><link>images/pasted-image-20251004170856.html</link><guid isPermaLink="false">Images/Pasted image 20251004170856.png</guid><pubDate>Sat, 04 Oct 2025 14:08:56 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251004164601]]></title><description><![CDATA[<img src="images/pasted-image-20251004164601.png" target="_self">]]></description><link>images/pasted-image-20251004164601.html</link><guid isPermaLink="false">Images/Pasted image 20251004164601.png</guid><pubDate>Sat, 04 Oct 2025 13:46:01 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251004163118]]></title><description><![CDATA[<img src="images/pasted-image-20251004163118.png" target="_self">]]></description><link>images/pasted-image-20251004163118.html</link><guid isPermaLink="false">Images/Pasted image 20251004163118.png</guid><pubDate>Sat, 04 Oct 2025 13:31:18 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251004162523]]></title><description><![CDATA[<img src="images/pasted-image-20251004162523.png" target="_self">]]></description><link>images/pasted-image-20251004162523.html</link><guid isPermaLink="false">Images/Pasted image 20251004162523.png</guid><pubDate>Sat, 04 Oct 2025 13:25:23 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[00 Basic 1 to 1 Interconnect]]></title><description><![CDATA[
This is more or less a summarization of Chapter 4, of Arm Fundamentals of SoC textbook, with note author's input.
Requestor &amp; Completer
The Component that is Requesting a resource/computation from another component, the completer, which completes this request.
ARM SoC: Single Word Transaction
The simplest form of transaction that we need an interconnect protocol to support is the movement of a single word from a requestor to a completer, that is, a single-word write transaction.
To Support Single Word Write Transaction we can simply add
The WR signal and the WRDATA are recieved on the same rising edge.
To Support Single Word Write Transaction we can simply add
The RD signal is received at rising edge 0 cycle 0, then the RDDATA on the next rising edge
<img alt="Pasted image 20251002163252.png" src="images/pasted-image-20251002163252.png" target="_self">Assumption &amp; disadvantages This assumes the completer can read/execute the request every clock cycle (1) We’ve assumed until now that there is only is one location, that is, only one register, in the completer (2) Asynchronous Reads
nothing prevents an interconnect protocol from permitting read data to be returned during cycle C (and, in fact, many protocols do allow this); however, this would imply that the overall read operation is asynchronous and we have stated that the interconnect we are building is synchronous.
<br><img alt="Pasted image 20251002164032.png" src="images/pasted-image-20251002164032.png" target="_self">A Major Disadvantage with the current interconnect that its support for back-to-back rapid transaction is lack-luster and leaves clock cycles to be optimized.
In the general case of a completer with an N-cycle end-to-end read latency, the maximum data throughput will be: To Mitigate this we can add a LENGTH Control Signal to signal to the completer how much data is given to it to write/read.<br><img alt="Pasted image 20251002164741.png" src="images/pasted-image-20251002164741.png" target="_self"><br><img alt="Pasted image 20251002164822.png" src="images/pasted-image-20251002164822.png" target="_self"><br>We Know <a data-tooltip-position="top" aria-label="^DW2" data-href="#^DW2" href="#^DW2" class="internal-link" target="_self" rel="noopener nofollow">Assumption (1)</a> is not true as the completer may need to process the request for many clock cycles.Terminiology
The mechanism through which a completer communicates its unavailability to a requestor is referred to as backpressure and a requestor waiting on a completer’s acknowledgement in this context is said to be stalled
To realize this feature, all we need is to implement a READY signal.
A transaction starts only when WR/RD and READY are both asserted in the same clock cycle.
Avoid Infinite Requestor Stalling
if a requestor wants to start a transaction, then it should assert its control signals and keep them asserted until the completer’s READY signal is asserted, Two Design Decesions are employed here: the requestor must not check the READY signal before deciding to assert its control signals because otherwise the completer may never know of the requestor’s intention to start a transaction
transactions cannot be interrupted once started because a requestor cannot deassert its control signals early, and all data words must be transmitted for both entities to acknowledge the transaction has finished. <br><img alt="Pasted image 20251002190522.png" src="images/pasted-image-20251002190522.png" target="_self">
Notice That the Completer Asserts/Deasserts the READY signal for each data write B C &amp; D.
Reading from completors may also incur many clock cycles, There needs to be a control signal that registers that the data within the RDDATA bus is valid.For a read transaction, the RD signal does not convey the validity of the RDDATA bus, but rather the validity of the control signals relevant to starting a transaction (ADDR, LENGTH). We need an additional completer-to-requestor signal to convey the validity of the RDDATA bus.
So RDDATAVALID is born: once completer fetches data, the RDDATAVALID, is asserted.
<br><img alt="Pasted image 20251002192210.png" src="images/pasted-image-20251002192210.png" target="_self"><br>Why would a Requestor Exert Backpressure on Completers? after all, shouldn’t a requestor know what it wants to write to the completer before initiating a burst transaction? This is the case when only a small amount of data needs transmitting, but if large amounts of data are involved some requestors may not know the extent of the payload they want to transmit at the outset. A common example would be a requestor reading from a FIFO.
<img alt="Pasted image 20251003182710.png" src="images/pasted-image-20251003182710.png" target="_self">
To Implement Requestor to Completer Backpressure, you can do this by deasserting the WR signal then asserting it again.<br><img alt="Pasted image 20251003183017.png" src="images/pasted-image-20251003183017.png" target="_self">We cannot Approach it as Write Transaction
Asserting RD when all of the data words from the previous transaction have not yet been received would be equivalent to the requestor telling the completer it wanted to start a new transaction as soon as the current one had terminated
Some protocols allow requestors to signal for completers future transactions, this done by giving the Completer a notice so that it can ensure its internal buffers accommodate the burst transaction.We are not those protocols so we will add a new signal RDDATAREADY which when deasserted by the requester, the requester can stall the completer, and the completer will assert\hold the current data in RDDATA bus until RDDATAREADY is asserted again.<br><img alt="Pasted image 20251003184041.png" src="images/pasted-image-20251003184041.png" target="_self"><br>Next on how to connect multiple requestors &amp; completers: <a data-href="01 Interconnect Fabric" href="root/digital-design/interconnect/01-interconnect-fabric.html" class="internal-link" target="_self" rel="noopener nofollow">01 Interconnect Fabric</a>]]></description><link>root/digital-design/interconnect/00-basic-1-to-1-interconnect.html</link><guid isPermaLink="false">Root/Digital Design/Interconnect/00 Basic 1 to 1 Interconnect.md</guid><pubDate>Sat, 04 Oct 2025 13:18:27 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251004153340]]></title><description><![CDATA[<img src="images/pasted-image-20251004153340.png" target="_self">]]></description><link>images/pasted-image-20251004153340.html</link><guid isPermaLink="false">Images/Pasted image 20251004153340.png</guid><pubDate>Sat, 04 Oct 2025 12:33:40 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[KWS SoC Portal]]></title><description><![CDATA[
This is a portal for the Keyword spotting SoC platform project, relevant notes are indexed here. <a data-href="GDB" href="root/debugging/gdb.html" class="internal-link" target="_self" rel="noopener nofollow">GDB</a> <br><a data-href="Iverilog &amp; GtkWave Simulation" href="root/digital-design/iverilog-&amp;-gtkwave-simulation.html" class="internal-link" target="_self" rel="noopener nofollow">Iverilog &amp; GtkWave Simulation</a> <br><a data-href="00 Basic 1 to 1 Interconnect" href="root/digital-design/interconnect/00-basic-1-to-1-interconnect.html" class="internal-link" target="_self" rel="noopener nofollow">00 Basic 1 to 1 Interconnect</a> <br><a data-href="00 NNoM" href="root/models/neural-network-libraries-for-embedded-systems/00-nnom.html" class="internal-link" target="_self" rel="noopener nofollow">00 NNoM</a>
]]></description><link>root/kws-soc-portal.html</link><guid isPermaLink="false">Root/KWS SoC Portal.md</guid><pubDate>Sat, 04 Oct 2025 12:23:55 GMT</pubDate></item><item><title><![CDATA[Pasted image 20251004135016]]></title><description><![CDATA[<img src="images/pasted-image-20251004135016.png" target="_self">]]></description><link>images/pasted-image-20251004135016.html</link><guid isPermaLink="false">Images/Pasted image 20251004135016.png</guid><pubDate>Sat, 04 Oct 2025 10:50:16 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251004133655]]></title><description><![CDATA[<img src="images/pasted-image-20251004133655.png" target="_self">]]></description><link>images/pasted-image-20251004133655.html</link><guid isPermaLink="false">Images/Pasted image 20251004133655.png</guid><pubDate>Sat, 04 Oct 2025 10:36:55 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251004125857]]></title><description><![CDATA[<img src="images/pasted-image-20251004125857.png" target="_self">]]></description><link>images/pasted-image-20251004125857.html</link><guid isPermaLink="false">Images/Pasted image 20251004125857.png</guid><pubDate>Sat, 04 Oct 2025 09:58:57 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251004123946]]></title><description><![CDATA[<img src="images/pasted-image-20251004123946.png" target="_self">]]></description><link>images/pasted-image-20251004123946.html</link><guid isPermaLink="false">Images/Pasted image 20251004123946.png</guid><pubDate>Sat, 04 Oct 2025 09:39:46 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251004115810]]></title><description><![CDATA[<img src="images/pasted-image-20251004115810.png" target="_self">]]></description><link>images/pasted-image-20251004115810.html</link><guid isPermaLink="false">Images/Pasted image 20251004115810.png</guid><pubDate>Sat, 04 Oct 2025 08:58:10 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251004114249]]></title><description><![CDATA[<img src="images/pasted-image-20251004114249.png" target="_self">]]></description><link>images/pasted-image-20251004114249.html</link><guid isPermaLink="false">Images/Pasted image 20251004114249.png</guid><pubDate>Sat, 04 Oct 2025 08:42:49 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003212955]]></title><description><![CDATA[<img src="images/pasted-image-20251003212955.png" target="_self">]]></description><link>images/pasted-image-20251003212955.html</link><guid isPermaLink="false">Images/Pasted image 20251003212955.png</guid><pubDate>Sat, 04 Oct 2025 07:39:11 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[00 NNoM]]></title><description><![CDATA[
NNoM is a high-level inference Neural Network library specifically for microcontrollers.
<img alt="Pasted image 20251003212416.png" src="images/pasted-image-20251003212416.png" target="_self">
NNoM uses a layer-based structure. The most benefit is the model structure can seem directly from the codes.
It also makes the model conversion from other layer-based libs (Keras, TensorLayer, Caffe) to NNoM model very straight forward. When use&nbsp;generate_model(model, x_test, name='weights.h')&nbsp;to generate NNoM model, it simply read the configuration out and rewrite it to C codes.<br>
<img alt="Pasted image 20251003212955.png" src="images/pasted-image-20251003212955.png" target="_self">
NNoM uses a compiler to manage the layer structure and other resources. After compiling, all layers inside the model will be put into a shortcut list per the running order. Besides that, arguments will be filled in and the memory will be allocated to each layer (Memory are reused in between layers). Therefore, no memory allocation performed in the runtime, performance is the same as running backend function directly.
The NNoM is more on managing the higher-level structure, context argument and memory. The actual arithmetics are done by the backend functions.
<br>Currently, NNoM supports a pure C backend and CMSIS-NN backend. The CMSIS-NN is a highly optimized low-level NN core for ARM-Cortex-M microcontroller. Please check the&nbsp;<a data-tooltip-position="top" aria-label="https://majianjia.github.io/nnom/Porting_and_Optimisation_Guide/" rel="noopener nofollow" class="external-link is-unresolved" href="https://majianjia.github.io/nnom/Porting_and_Optimisation_Guide/" target="_self">optimization guide</a>&nbsp;for utilization.
NNoM is a higher-level inference framework. The most obvious feature is the human understandable interface.
It is also a layer-based framework, instead of operator-based. A layer might contain a few operators.
It natively supports complex model structure. High-efficiency network always benefited from complex structure.
It provides layer-to-layer analysis to help developer optimize their models. Notes: NNoM now supports both HWC and CHW formats. Some operation might not support both format currently. Please check the tables for the current status. Core LayersRNN LayersActivations<br>Activation can be used by itself as layer, or can be attached to the previous layer as&nbsp;<a data-tooltip-position="top" aria-label="https://majianjia.github.io/nnom/docs/A_Temporary_Guide_to_NNoM.md#addictionlly-activation-apis" rel="noopener nofollow" class="external-link is-unresolved" href="https://majianjia.github.io/nnom/docs/A_Temporary_Guide_to_NNoM.md#addictionlly-activation-apis" target="_self">"actail"</a>&nbsp;to reduce memory cost.There is no Struct API for activation currently, since activation are not usually used as a layer.Pooling LayersMatrix Operations LayersNNoM now use the local pure C backend implementation by default. Thus, there is no special dependency needed.NNoM currently only support 8 bit weights and 8 bit activations. The model will be quantised through model conversion&nbsp;generate_model(model, x_test, name='weights.h').The input data (activations) will need to be quantised then feed to the model.Performances vary from chip to chip. Efficiencies are more constant.We can use&nbsp;Multiply–accumulate operation (MAC) per Hz (MACops/Hz)&nbsp;to evaluate the efficiency. It simply means how many MAC can be done in one cycle.Currently, NNoM only count MAC operations on Convolution layers and Dense layers since other layers (pooling, padding) are much lesser.The script currently does not support implicit act:x = Dense(32, activation="relu")(x)
Use the explicit activation instead.x = Dense(32)(x)
x = Relu()(x)
Evaluation is equally important to building the model.<br>In NNoM, we provide a few different methods to evaluate the model. The details are list in&nbsp;<a data-tooltip-position="top" aria-label="https://majianjia.github.io/nnom/api_nnom_utils/" rel="noopener nofollow" class="external-link is-unresolved" href="https://majianjia.github.io/nnom/api_nnom_utils/" target="_self">Evaluation Methods</a>. If your system support print through a console (such as serial port), the evaluation can be printed on the console.Firstly, the model structure is printed during compiling in&nbsp;model_compile(), which is normally called in&nbsp;nnom_model_create().Secondly, the runtime performance is printed by&nbsp;model_stat().Thirdly, there is a set of&nbsp;prediction_*()&nbsp;APIs to validate a set of testing data and print out Top-K accuracy, confusion matrix and other info.This is what a typical model looks like in the&nbsp;weights.h&nbsp;or&nbsp;model.h&nbsp;or whatever you name it. These codes are generated by the script. In user's&nbsp;main(), call&nbsp;nnom_model_create()&nbsp;will create and compile the model./* nnom model */
static int8_t nnom_input_data[784];
static int8_t nnom_output_data[10];
static nnom_model_t* nnom_model_create(void)
{ static nnom_model_t model; nnom_layer_t* layer[20]; new_model(&amp;model); layer[0] = Input(shape(28, 28, 1), nnom_input_data); layer[1] = model.hook(Conv2D(12, kernel(3, 3), stride(1, 1), PADDING_SAME, &amp;conv2d_1_w, &amp;conv2d_1_b), layer[0]); layer[2] = model.active(act_relu(), layer[1]); layer[3] = model.hook(MaxPool(kernel(2, 2), stride(2, 2), PADDING_SAME), layer[2]); layer[4] = model.hook(Cropping(border(1,2,3,4)), layer[3]); layer[5] = model.hook(Conv2D(24, kernel(3, 3), stride(1, 1), PADDING_SAME, &amp;conv2d_2_w, &amp;conv2d_2_b), layer[4]); layer[6] = model.active(act_relu(), layer[5]); layer[7] = model.hook(MaxPool(kernel(4, 4), stride(4, 4), PADDING_SAME), layer[6]); layer[8] = model.hook(ZeroPadding(border(1,2,3,4)), layer[7]); layer[9] = model.hook(Conv2D(24, kernel(3, 3), stride(1, 1), PADDING_SAME, &amp;conv2d_3_w, &amp;conv2d_3_b), layer[8]); layer[10] = model.active(act_relu(), layer[9]); layer[11] = model.hook(UpSample(kernel(2, 2)), layer[10]); layer[12] = model.hook(Conv2D(48, kernel(3, 3), stride(1, 1), PADDING_SAME, &amp;conv2d_4_w, &amp;conv2d_4_b), layer[11]); layer[13] = model.active(act_relu(), layer[12]); layer[14] = model.hook(MaxPool(kernel(2, 2), stride(2, 2), PADDING_SAME), layer[13]); layer[15] = model.hook(Dense(64, &amp;dense_1_w, &amp;dense_1_b), layer[14]); layer[16] = model.active(act_relu(), layer[15]); layer[17] = model.hook(Dense(10, &amp;dense_2_w, &amp;dense_2_b), layer[16]); layer[18] = model.hook(Softmax(), layer[17]); layer[19] = model.hook(Output(shape(10,1,1), nnom_output_data), layer[18]); model_compile(&amp;model, layer[0], layer[19]); return &amp;model;
}
This is an example printed by&nbsp;model_compile(), which is normally called by&nbsp;nnom_model_create().Start compiling model...
Layer(#) Activation output shape ops(MAC) mem(in, out, buf) mem blk lifetime
-------------------------------------------------------------------------------------------------
#1 Input - - ( 28, 28, 1) ( 784, 784, 0) 1 - - - - - - - #2 Conv2D - ReLU - ( 28, 28, 12) 84k ( 784, 9408, 36) 1 1 1 - - - - - #3 MaxPool - - ( 14, 14, 12) ( 9408, 2352, 0) 1 1 1 - - - - - #4 Cropping - - ( 11, 7, 12) ( 2352, 924, 0) 1 1 - - - - - - #5 Conv2D - ReLU - ( 11, 7, 24) 199k ( 924, 1848, 432) 1 1 1 - - - - - #6 MaxPool - - ( 3, 2, 24) ( 1848, 144, 0) 1 1 1 - - - - - #7 ZeroPad - - ( 6, 9, 24) ( 144, 1296, 0) 1 1 - - - - - - #8 Conv2D - ReLU - ( 6, 9, 24) 279k ( 1296, 1296, 864) 1 1 1 - - - - - #9 UpSample - - ( 12, 18, 24) ( 1296, 5184, 0) 1 - 1 - - - - - #10 Conv2D - ReLU - ( 12, 18, 48) 2.23M ( 5184, 10368, 864) 1 1 1 - - - - - #11 MaxPool - - ( 6, 9, 48) ( 10368, 2592, 0) 1 1 1 - - - - - #12 Dense - ReLU - ( 64, 1, 1) 165k ( 2592, 64, 5184) 1 1 1 - - - - - #13 Dense - - ( 10, 1, 1) 640 ( 64, 10, 128) 1 1 1 - - - - - #14 Softmax - - ( 10, 1, 1) ( 10, 10, 0) 1 1 - - - - - - #15 Output - - ( 10, 1, 1) ( 10, 10, 0) 1 - - - - - - - -------------------------------------------------------------------------------------------------
Memory cost by each block: blk_0:5184 blk_1:2592 blk_2:10368 blk_3:0 blk_4:0 blk_5:0 blk_6:0 blk_7:0 Total memory cost by network buffers: 18144 bytes
Compling done in 179 ms It shows the run order, Layer names, activations, the output shape of the layer, the operation counts, the buffer size, and the memory block assignments.Later, it prints the maximum memory cost for each memory block. Since the memory block is shared between layers, the model only uses 3 memory blocks, altogether gives a sum memory cost by&nbsp;18144 Bytes.This is an example printed by&nbsp;model_stat().<br>
This method requires a microsecond timestamp porting, check&nbsp;<a data-tooltip-position="top" aria-label="https://majianjia.github.io/nnom/Porting_and_Optimisation_Guide/" rel="noopener nofollow" class="external-link is-unresolved" href="https://majianjia.github.io/nnom/Porting_and_Optimisation_Guide/" target="_self">porting guide</a>
Print running stat..
Layer(#) - Time(us) ops(MACs) ops/us --------------------------------------------------------
#1 Input - 11 #2 Conv2D - 5848 84k 14.47
#3 MaxPool - 698 #4 Cropping - 16 #5 Conv2D - 3367 199k 59.27
#6 MaxPool - 346 #7 ZeroPad - 36 #8 Conv2D - 4400 279k 63.62
#9 UpSample - 116 #10 Conv2D - 33563 2.23M 66.72
#11 MaxPool - 2137 #12 Dense - 2881 165k 57.58
#13 Dense - 16 640 40.00
#14 Softmax - 3 #15 Output - 1 Summary:
Total ops (MAC): 2970208(2.97M)
Prediction time :53439us
Efficiency 55.58 ops/us
NNOM: Total Mem: 20236 Calling this method will print out the time cost for each layer, and the efficiency in (MACops/us) of this layer.This is very important when designing your ad-hoc model.As mention, NNoM will allocate memory to the layer during the compiling phase. Memory block is a minimum unit for a layer to apply. For example, convolution layers normally apply one block for input data, one block for output data and one block for the intermediate data buffer.Layer(#) Activation output shape ops(MAC) mem(in, out, buf) mem blk lifetime
-------------------------------------------------------------------------------------------------
#2 Conv2D - ReLU - ( 28, 28, 12) 84k ( 784, 9408, 36) 1 1 1 - - - - - The example shows input buffer size&nbsp;784, output buffer size&nbsp;9408, intermediate buffer size&nbsp;36. The following&nbsp;mem blk lifetime&nbsp;means how long does the memory block last. All three block last only one step, they will be freed after the layer. In NNoM, the output memory will be pass directly to the next layer(s) as input buffer, so there is no memory copy cost and memory allocation in between layers.Lets say if we want to classify the MNIST hand writing dataset. This is what you normally do with Keras.model = Sequential()
model.add(Dense(32, input_dim=784))
model.add(Activation('relu'))
model.add(Dense(10))
Each operation in Keras are defined by "Layer", same as we did in NNoM. The terms are different from Tensorflow.After the&nbsp;model&nbsp;is trained, the weights and parameters are already functional. We can now convert it to C language files then put it in your MCU project.
The result of this step is a single&nbsp;weights.h&nbsp;file, which contains everything you need.
<br>To convert the model, NNoM has provided an simple API&nbsp;generate_model()<a data-tooltip-position="top" aria-label="https://majianjia.github.io/nnom/api_nnom_utils/" rel="noopener nofollow" class="external-link is-unresolved" href="https://majianjia.github.io/nnom/api_nnom_utils/" target="_self">API</a>&nbsp;to automatically do the job. Simply pass the&nbsp;model&nbsp;and the test dataset to it. It will do all the magics for you.generate_model(model, x_test, name='weights.h')
When the conversion is finished, you will find a new&nbsp;weights.h&nbsp;under your working folder. Simply copy the file to your MCU project, and call&nbsp;model = nnom_model_create();&nbsp;inside you&nbsp;main().Below is what you should do in practice.#include "nnom.h"
#include "weights.h" int main(void)
{ nnom_model_t *model; model = nnom_model_create(); model_run(model);
}
Then, your model is now running on you MCU. If you have supported&nbsp;printf&nbsp;on your MCU, you should see the compiling info on your consoles.Compiling logging similar to this:Start compiling model...
Layer(#) Activation output shape ops(MAC) mem(in, out, buf) mem blk lifetime
-------------------------------------------------------------------------------------------------
#1 Input - - ( 28, 28, 1) ( 784, 784, 0) 1 - - - - - - - #2 Conv2D - ReLU - ( 28, 28, 12) 84k ( 784, 9408, 36) 1 1 3 - - - - - #3 MaxPool - - ( 14, 14, 12) ( 9408, 2352, 0) 1 2 3 - - - - - #4 UpSample - - ( 28, 28, 12) ( 2352, 9408, 0) 1 2 2 - - - - - #5 Conv2D - - ( 14, 14, 12) 254k ( 2352, 2352, 432) 1 1 2 1 1 - - - #6 Conv2D - - ( 28, 28, 12) 1.01M ( 9408, 9408, 432) 1 1 2 1 1 - - - #7 Add - - ( 28, 28, 12) ( 9408, 9408, 0) 1 1 1 1 1 - - - #8 MaxPool - - ( 14, 14, 12) ( 9408, 2352, 0) 1 1 1 2 1 - - - #9 Conv2D - - ( 14, 14, 12) 254k ( 2352, 2352, 432) 1 1 1 2 1 - - - #10 AvgPool - - ( 7, 7, 12) ( 2352, 588, 168) 1 1 1 1 1 1 - - #11 AvgPool - - ( 14, 14, 12) ( 9408, 2352, 336) 1 1 1 1 1 1 - - #12 Add - - ( 14, 14, 12) ( 2352, 2352, 0) 1 1 - 1 1 1 - - #13 MaxPool - - ( 7, 7, 12) ( 2352, 588, 0) 1 1 1 2 - 1 - - #14 UpSample - - ( 14, 14, 12) ( 588, 2352, 0) 1 1 - 2 - 1 - - #15 Add - - ( 14, 14, 12) ( 2352, 2352, 0) 1 1 1 1 - 1 - - #16 MaxPool - - ( 7, 7, 12) ( 2352, 588, 0) 1 1 1 1 - 1 - - #17 Conv2D - - ( 7, 7, 12) 63k ( 588, 588, 432) 1 1 1 1 - 1 - - #18 Add - - ( 7, 7, 12) ( 588, 588, 0) 1 1 1 - - 1 - - #19 Concat - - ( 7, 7, 24) ( 1176, 1176, 0) 1 1 1 - - - - - #20 Dense - ReLU - ( 96, 1, 1) 112k ( 1176, 96, 2352) 1 1 1 - - - - - #21 Dense - - ( 10, 1, 1) 960 ( 96, 10, 192) 1 1 1 - - - - - #22 Softmax - - ( 10, 1, 1) ( 10, 10, 0) 1 - 1 - - - - - #23 Output - - ( 10, 1, 1) ( 10, 10, 0) 1 - - - - - - - -------------------------------------------------------------------------------------------------
Memory cost by each block: blk_0:9408 blk_1:9408 blk_2:9408 blk_3:9408 blk_4:2352 blk_5:588 blk_6:0 blk_7:0 Total memory cost by network buffers: 40572 bytes
Compling done in 76 ms You can now use the model to predict your data.
Firstly, filling the input buffer&nbsp;nnom_input_buffer[]&nbsp;with your own data(image, signals) which is defined in&nbsp;weights.h.
Secondly, call&nbsp;model_run(model);&nbsp;to do your prediction.
Thirdly, read your result from&nbsp;nnom_output_buffer[]. The maximum number is the results.
Now, please do check NNoM examples for more fancy methods.<br>Next <a data-href="01 ExecuTorch" href=".html" class="internal-link" target="_self" rel="noopener nofollow">01 ExecuTorch</a>]]></description><link>root/models/neural-network-libraries-for-embedded-systems/00-nnom.html</link><guid isPermaLink="false">Root/Models/Neural Network Libraries for Embedded Systems/00 NNoM.md</guid><pubDate>Sat, 04 Oct 2025 07:39:11 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003212416]]></title><description><![CDATA[<img src="images/pasted-image-20251003212416.png" target="_self">]]></description><link>images/pasted-image-20251003212416.html</link><guid isPermaLink="false">Images/Pasted image 20251003212416.png</guid><pubDate>Sat, 04 Oct 2025 07:39:11 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003191451]]></title><description><![CDATA[<img src="images/pasted-image-20251003191451.png" target="_self">]]></description><link>images/pasted-image-20251003191451.html</link><guid isPermaLink="false">Images/Pasted image 20251003191451.png</guid><pubDate>Fri, 03 Oct 2025 16:14:51 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003191255]]></title><description><![CDATA[<img src="images/pasted-image-20251003191255.png" target="_self">]]></description><link>images/pasted-image-20251003191255.html</link><guid isPermaLink="false">Images/Pasted image 20251003191255.png</guid><pubDate>Fri, 03 Oct 2025 16:12:55 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003190823]]></title><description><![CDATA[<img src="images/pasted-image-20251003190823.png" target="_self">]]></description><link>images/pasted-image-20251003190823.html</link><guid isPermaLink="false">Images/Pasted image 20251003190823.png</guid><pubDate>Fri, 03 Oct 2025 16:08:23 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003190142]]></title><description><![CDATA[<img src="images/pasted-image-20251003190142.png" target="_self">]]></description><link>images/pasted-image-20251003190142.html</link><guid isPermaLink="false">Images/Pasted image 20251003190142.png</guid><pubDate>Fri, 03 Oct 2025 16:01:42 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003190025]]></title><description><![CDATA[<img src="images/pasted-image-20251003190025.png" target="_self">]]></description><link>images/pasted-image-20251003190025.html</link><guid isPermaLink="false">Images/Pasted image 20251003190025.png</guid><pubDate>Fri, 03 Oct 2025 16:00:25 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003185851]]></title><description><![CDATA[<img src="images/pasted-image-20251003185851.png" target="_self">]]></description><link>images/pasted-image-20251003185851.html</link><guid isPermaLink="false">Images/Pasted image 20251003185851.png</guid><pubDate>Fri, 03 Oct 2025 15:58:51 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003184213]]></title><description><![CDATA[<img src="images/pasted-image-20251003184213.png" target="_self">]]></description><link>images/pasted-image-20251003184213.html</link><guid isPermaLink="false">Images/Pasted image 20251003184213.png</guid><pubDate>Fri, 03 Oct 2025 15:42:13 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003184041]]></title><description><![CDATA[<img src="images/pasted-image-20251003184041.png" target="_self">]]></description><link>images/pasted-image-20251003184041.html</link><guid isPermaLink="false">Images/Pasted image 20251003184041.png</guid><pubDate>Fri, 03 Oct 2025 15:40:41 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003183017]]></title><description><![CDATA[<img src="images/pasted-image-20251003183017.png" target="_self">]]></description><link>images/pasted-image-20251003183017.html</link><guid isPermaLink="false">Images/Pasted image 20251003183017.png</guid><pubDate>Fri, 03 Oct 2025 15:30:17 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251003182710]]></title><description><![CDATA[<img src="images/pasted-image-20251003182710.png" target="_self">]]></description><link>images/pasted-image-20251003182710.html</link><guid isPermaLink="false">Images/Pasted image 20251003182710.png</guid><pubDate>Fri, 03 Oct 2025 15:27:10 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251002192210]]></title><description><![CDATA[<img src="images/pasted-image-20251002192210.png" target="_self">]]></description><link>images/pasted-image-20251002192210.html</link><guid isPermaLink="false">Images/Pasted image 20251002192210.png</guid><pubDate>Thu, 02 Oct 2025 16:22:10 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Iverilog & GtkWave Simulation]]></title><description><![CDATA[Make Sure your test-bench dumps waveform .vcd in the output, by appending: initial
begin $dumpfile("&lt;module name&gt;_tb.vcd"); $dumpvars(0,test);
end
$ iverilog -o &lt;output_filename&gt; &lt;testbench&gt;.v &lt;verilog_sources&gt;.v $ vvp &lt;output_filename&gt; $ gtkwave &lt;vcd_filename&gt;.vcd &amp;
Directory structure-rw-rw-r-- 1 waseem waseem 939 Oct 2 14:43 ahbl_master_tb.v
-rw-rw-r-- 1 waseem waseem 291 Oct 2 14:43 readme.md
drwxrwxr-x 2 waseem waseem 4.0K Oct 2 14:55 src/
iverilog -o out ahbl_master_tb.v src/ahbl_master.v src/ahbl_slave.v src/ahbl_splitter_4.v
OR you can use -I Option or wildcards *iverilog -o out ahbl_master_tb.v src/*.v
gtkwave &lt;vcd_filename&gt;.vcd &amp;
# Source files
V_SOURCES = $(wildcard src/*.v)
TB_SOURCE = ahbl_master_tb.v # Output files
OUT_FILE = out
# Nasty string concatenation trick to maintain consistency
VCD_FILE = $(TB_SOURCE)cd # Default target: runs the simulation and opens the waveform
all: wave # Compile the Verilog sources
$(OUT_FILE): $(V_SOURCES) $(TB_SOURCE) iverilog -o $(OUT_FILE) $(TB_SOURCE) $(V_SOURCES) # Run the simulation to generate the VCD file
$(VCD_FILE): $(OUT_FILE) vvp $(OUT_FILE) # Target to run the simulation
sim: $(VCD_FILE) # Open the waveform in GTKWave
wave: $(VCD_FILE) gtkwave $(VCD_FILE) &amp; # Clean up generated files
clean: rm -f $(OUT_FILE) $(VCD_FILE)
]]></description><link>root/digital-design/iverilog-&amp;-gtkwave-simulation.html</link><guid isPermaLink="false">Root/Digital Design/Iverilog &amp; GtkWave Simulation.md</guid><pubDate>Thu, 02 Oct 2025 16:12:58 GMT</pubDate></item><item><title><![CDATA[Pasted image 20251002190522]]></title><description><![CDATA[<img src="images/pasted-image-20251002190522.png" target="_self">]]></description><link>images/pasted-image-20251002190522.html</link><guid isPermaLink="false">Images/Pasted image 20251002190522.png</guid><pubDate>Thu, 02 Oct 2025 16:05:22 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[GDB]]></title><description><![CDATA[g++ &lt;file-name&gt; -g -o &lt;executable-name&gt;-g debugging symbols
-o output executablerun
lay nextbr &lt;symbol (file,method,variable,line)&gt;info &lt;command&gt;
info break : show breakpoints enable 1 : enable (ID of breakpoint)
disable 1 : disable (ID of breakpoint)Overloaded functions when putting a breakpoint on an overloaded function GDB will put the breakpoints on all the functions of the same name
print &lt;var&gt;
inspect &lt;stl structure&gt;set &lt;var&gt; = &lt;value&gt;nsfincontinue or cneed -lpthread flag when compilinginfo threads or thswitching threads
t &lt;id&gt; backtrace of the thread
btswitching frames
f &lt;id&gt;b &lt;function&gt; if &lt;variable&gt; &lt;operator&gt; &lt;value&gt;break on function if condition met--release and --g flagscompiler optimization flags-03
-02
-01 (Default) -g3 debugging with optimiation level 3
]]></description><link>root/debugging/gdb.html</link><guid isPermaLink="false">Root/Debugging/GDB.md</guid><pubDate>Thu, 02 Oct 2025 16:05:14 GMT</pubDate></item><item><title><![CDATA[Pasted image 20251002164822]]></title><description><![CDATA[<img src="images/pasted-image-20251002164822.png" target="_self">]]></description><link>images/pasted-image-20251002164822.html</link><guid isPermaLink="false">Images/Pasted image 20251002164822.png</guid><pubDate>Thu, 02 Oct 2025 13:48:22 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251002164741]]></title><description><![CDATA[<img src="images/pasted-image-20251002164741.png" target="_self">]]></description><link>images/pasted-image-20251002164741.html</link><guid isPermaLink="false">Images/Pasted image 20251002164741.png</guid><pubDate>Thu, 02 Oct 2025 13:47:41 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251002164032]]></title><description><![CDATA[<img src="images/pasted-image-20251002164032.png" target="_self">]]></description><link>images/pasted-image-20251002164032.html</link><guid isPermaLink="false">Images/Pasted image 20251002164032.png</guid><pubDate>Thu, 02 Oct 2025 13:40:32 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20251002163252]]></title><description><![CDATA[<img src="images/pasted-image-20251002163252.png" target="_self">]]></description><link>images/pasted-image-20251002163252.html</link><guid isPermaLink="false">Images/Pasted image 20251002163252.png</guid><pubDate>Thu, 02 Oct 2025 13:32:52 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[02 AHB-Lite Protocol]]></title><link>root/digital-design/interconnect/02-ahb-lite-protocol.html</link><guid isPermaLink="false">Root/Digital Design/Interconnect/02 AHB-Lite Protocol.md</guid><pubDate>Thu, 02 Oct 2025 13:06:44 GMT</pubDate></item><item><title><![CDATA[00 Basic Interconnect]]></title><description><![CDATA[
This is more or less a summarization of Chapter 4, of Arm Fundamentals of SoC textbook Requestor &amp; Completer
The Component that is Requesting a resource/computation from another component, the completer, which completes this request.
ARM SoC: Single Word Transaction
The simplest form of transaction that we need an interconnect protocol to support is the movement of a single word from a requestor to a completer, that is, a single-word write transaction.
To Support Single Word Write Transaction we can simply add
The WR signal and the WRDATA are recieved on the same rising edge.
To Support Single Word Write Transaction we can simply add
The RD signal is received at rising edge 0 cycle 0, then the RDDATA on the next rising edge
<img alt="Pasted image 20251002163252.png" src="images/pasted-image-20251002163252.png" target="_self">Assumption &amp; disadvantages This assumes the completer can read/execute the request every clock cycle (1) We’ve assumed until now that there is only is one location, that is, only one register, in the completer (2) Asynchronous Reads
nothing prevents an interconnect protocol from permitting read data to be returned during cycle C (and, in fact, many protocols do allow this); however, this would imply that the overall read operation is asynchronous and we have stated that the interconnect we are building is synchronous.
<br><img alt="Pasted image 20251002164032.png" src="images/pasted-image-20251002164032.png" target="_self">A Major Disadvantage with the current interconnect that its support for back-to-back rapid transaction is lack-luster and leaves clock cycles to be optimized.
In the general case of a completer with an N-cycle end-to-end read latency, the maximum data throughput will be: To Mitigate this we can add a LENGTH Control Signal to signal to the completer how much data is given to it to write/read.<br><img alt="Pasted image 20251002164741.png" src="images/pasted-image-20251002164741.png" target="_self"><br><img alt="Pasted image 20251002164822.png" src="images/pasted-image-20251002164822.png" target="_self"><br>We Know <a data-tooltip-position="top" aria-label="^DW2" data-href="#^DW2" href="#^DW2" class="internal-link" target="_self" rel="noopener nofollow">Assumption (1)</a> is not true as the completer may need to process the request for many clock cycles.Terminiology
The mechanism through which a completer communicates its unavailability to a requestor is referred to as backpressure and a requestor waiting on a completer’s acknowledgement in this context is said to be stalled
To realize this feature, all we need is to implement a READY signal.
A transaction starts only when WR/RD and READY are both asserted in the same clock cycle.
Avoid Infinite Requestor Stalling
if a requestor wants to start a transaction, then it should assert its control signals and keep them asserted until the completer’s READY signal is asserted, Two Design Decesions are employed here: the requestor must not check the READY signal before deciding to assert its control signals because otherwise the completer may never know of the requestor’s intention to start a transaction
transactions cannot be interrupted once started because a requestor cannot deassert its control signals early, and all data words must be transmitted for both entities to acknowledge the transaction has finished. <br><img alt="Pasted image 20251002190522.png" src="images/pasted-image-20251002190522.png" target="_self">
Notice That the Completer Asserts/Deasserts the READY signal for each data write B C &amp; D.
Reading from completors may also incur many clock cycles, There needs to be a control signal that registers that the data within the RDDATA bus is valid.For a read transaction, the RD signal does not convey the validity of the RDDATA bus, but rather the validity of the control signals relevant to starting a transaction (ADDR, LENGTH). We need an additional completer-to-requestor signal to convey the validity of the RDDATA bus.
So RDDATAVALID is born: once completer fetches data, the RDDATAVALID, is asserted.
<br><img alt="Pasted image 20251002192210.png" src="images/pasted-image-20251002192210.png" target="_self"><br>Next <a data-href="01 AHB-Lite Protocol" href="root/digital-design/interconnect/01-ahb-lite-protocol.html" class="internal-link" target="_self" rel="noopener nofollow">01 AHB-Lite Protocol</a>]]></description><link>root/digital-design/interconnect/00-basic-interconnect.html</link><guid isPermaLink="false">Root/Digital Design/Interconnect/00 Basic Interconnect.md</guid><pubDate>Fri, 03 Oct 2025 14:47:51 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[00 Basic Interconnect]]></title><description><![CDATA[
This is more or less a summarization of Chapter 4, of Arm Fundamentals of SoC textbook Requestor &amp; Completer
The Component that is Requesting a resource/computation from another component, the completer, which completes this request.
ARM SoC: Single Word Transaction
The simplest form of transaction that we need an interconnect protocol to support is the movement of a single word from a requestor to a completer, that is, a single-word write transaction.
To Support Single Word Write Transaction we can simply add
The WR signal and the WRDATA are recieved on the same rising edge.
To Support Single Word Write Transaction we can simply add
The RD signal is received at rising edge 0 cycle 0, then the RDDATA on the next rising edge
“Pasted image 20251002163252.png” could not be found.Assumption &amp; disadvantages This assumes the completer can read/execute the request every clock cycle (1) We’ve assumed until now that there is only is one location, that is, only one register, in the completer (2) Asynchronous Reads
nothing prevents an interconnect protocol from permitting read data to be returned during cycle C (and, in fact, many protocols do allow this); however, this would imply that the overall read operation is asynchronous and we have stated that the interconnect we are building is synchronous.
“Pasted image 20251002164032.png” could not be found.A Major Disadvantage with the current interconnect that its support for back-to-back rapid transaction is lack-luster and leaves clock cycles to be optimized.
In the general case of a completer with an N-cycle end-to-end read latency, the maximum data throughput will be: To Mitigate this we can add a LENGTH Control Signal to signal to the completer how much data is given to it to write/read.“Pasted image 20251002164741.png” could not be found.“Pasted image 20251002164822.png” could not be found.We Know <a data-tooltip-position="top" aria-label="^DW2" data-href="#^DW2" href="#^DW2" class="internal-link" target="_self" rel="noopener nofollow">Assumption (1)</a> is not true as the completer may need to process the request for many clock cycles.Terminiology
The mechanism through which a completer communicates its unavailability to a requestor is referred to as backpressure and a requestor waiting on a completer’s acknowledgement in this context is said to be stalled
To realize this feature, all we need is to implement a READY signal.
A transaction starts only when WR/RD and READY are both asserted in the same clock cycle.
Avoid Infinite Requestor Stalling
if a requestor wants to start a transaction, then it should assert its control signals and keep them asserted until the completer’s READY signal is asserted, Two Design Decesions are employed here: the requestor must not check the READY signal before deciding to assert its control signals because otherwise the completer may never know of the requestor’s intention to start a transaction
transactions cannot be interrupted once started because a requestor cannot deassert its control signals early, and all data words must be transmitted for both entities to acknowledge the transaction has finished. “Pasted image 20251002190522.png” could not be found.
Notice That the Completer Asserts/Deasserts the READY signal for each data write B C &amp; D.
Reading from completors may also incur many clock cycles, There needs to be a control signal that registers that the data within the RDDATA bus is valid.For a read transaction, the RD signal does not convey the validity of the RDDATA bus, but rather the validity of the control signals relevant to starting a transaction (ADDR, LENGTH). We need an additional completer-to-requestor signal to convey the validity of the RDDATA bus.
So RDDATAVALID is born: once completer fetches data, the RDDATAVALID, is asserted.
“Pasted image 20251002192210.png” could not be found.<br>Next <a data-href="01 AHB-Lite Protocol" href="root/digital-design/interconnect/01-ahb-lite-protocol.html" class="internal-link" target="_self" rel="noopener nofollow">01 AHB-Lite Protocol</a>]]></description><link>root/digital-design/interconnect/00-basic-interconnect.html</link><guid isPermaLink="false">root/Digital Design/Interconnect/00 Basic Interconnect.md</guid><pubDate>Thu, 02 Oct 2025 16:34:10 GMT</pubDate></item><item><title><![CDATA[Iverilog & GtkWave Simulation]]></title><description><![CDATA[Make Sure your test-bench dumps waveform .vcd in the output, by appending: initial
begin $dumpfile("&lt;module name&gt;_tb.vcd"); $dumpvars(0,test);
end
$ iverilog -o &lt;output_filename&gt; &lt;testbench&gt;.v &lt;verilog_sources&gt;.v $ vvp &lt;output_filename&gt; $ gtkwave &lt;vcd_filename&gt;.vcd &amp;
Directory structure-rw-rw-r-- 1 waseem waseem 939 Oct 2 14:43 ahbl_master_tb.v
-rw-rw-r-- 1 waseem waseem 291 Oct 2 14:43 readme.md
drwxrwxr-x 2 waseem waseem 4.0K Oct 2 14:55 src/
iverilog -o out ahbl_master_tb.v src/ahbl_master.v src/ahbl_slave.v src/ahbl_splitter_4.v
OR you can use -I Option or wildcards *iverilog -o out ahbl_master_tb.v src/*.v
gtkwave &lt;vcd_filename&gt;.vcd &amp;
# Source files
V_SOURCES = $(wildcard src/*.v)
TB_SOURCE = ahbl_master_tb.v # Output files
OUT_FILE = out
# Nasty string concatenation trick to maintain consistency
VCD_FILE = $(TB_SOURCE)cd # Default target: runs the simulation and opens the waveform
all: wave # Compile the Verilog sources
$(OUT_FILE): $(V_SOURCES) $(TB_SOURCE) iverilog -o $(OUT_FILE) $(TB_SOURCE) $(V_SOURCES) # Run the simulation to generate the VCD file
$(VCD_FILE): $(OUT_FILE) vvp $(OUT_FILE) # Target to run the simulation
sim: $(VCD_FILE) # Open the waveform in GTKWave
wave: $(VCD_FILE) gtkwave $(VCD_FILE) &amp; # Clean up generated files
clean: rm -f $(OUT_FILE) $(VCD_FILE)
]]></description><link>root/digital-design/iverilog-&amp;-gtkwave-simulation.html</link><guid isPermaLink="false">root/Digital Design/Iverilog &amp; GtkWave Simulation.md</guid><pubDate>Thu, 02 Oct 2025 16:12:58 GMT</pubDate></item><item><title><![CDATA[GDB]]></title><description><![CDATA[g++ &lt;file-name&gt; -g -o &lt;executable-name&gt;-g debugging symbols
-o output executablerun
lay nextbr &lt;symbol (file,method,variable,line)&gt;info &lt;command&gt;
info break : show breakpoints enable 1 : enable (ID of breakpoint)
disable 1 : disable (ID of breakpoint)Overloaded functions when putting a breakpoint on an overloaded function GDB will put the breakpoints on all the functions of the same name
print &lt;var&gt;
inspect &lt;stl structure&gt;set &lt;var&gt; = &lt;value&gt;nsfincontinue or cneed -lpthread flag when compilinginfo threads or thswitching threads
t &lt;id&gt; backtrace of the thread
btswitching frames
f &lt;id&gt;b &lt;function&gt; if &lt;variable&gt; &lt;operator&gt; &lt;value&gt;break on function if condition met--release and --g flagscompiler optimization flags-03
-02
-01 (Default) -g3 debugging with optimiation level 3
]]></description><link>root/debugging/gdb.html</link><guid isPermaLink="false">root/Debugging/GDB.md</guid><pubDate>Thu, 02 Oct 2025 16:05:14 GMT</pubDate></item><item><title><![CDATA[01 AHB-Lite Protocol]]></title><link>root/digital-design/interconnect/01-ahb-lite-protocol.html</link><guid isPermaLink="false">root/Digital Design/Interconnect/01 AHB-Lite Protocol.md</guid><pubDate>Thu, 02 Oct 2025 13:06:44 GMT</pubDate></item></channel></rss>